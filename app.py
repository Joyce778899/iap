# app.py â€” IAP ORCAT Onlineï¼ˆä¸¥æ ¼æ¨¡å¼ï½œè´¢æŠ¥è¡¨å¤´=ç¬¬3è¡Œï½œä½¿ç”¨â€œæ±‡ç‡â€åˆ—ï½œç¨³å¥å¸ç§è§£æ&æœ‰æ•ˆè¡Œç­›é€‰ï¼‰

import re
import numpy as np
import pandas as pd
import streamlit as st

st.set_page_config(page_title="IAP â€” ORCAT Online (Strict+Robust)", page_icon="ğŸ’¼", layout="wide")
st.title("ğŸ’¼ IAP â€” ORCAT Onlineï¼ˆä¸¥æ ¼ï½œè´¢æŠ¥è¡¨å¤´=ç¬¬3è¡Œï½œä½¿ç”¨è´¢æŠ¥æ±‡ç‡ï¼‰")

with st.expander("ä½¿ç”¨è¯´æ˜", expanded=False):
    st.markdown("""
**â‘  è´¢æŠ¥ï¼ˆCSV/XLSXï¼Œè¡¨å¤´=ç¬¬3è¡Œï¼‰**  
- `å›½å®¶æˆ–åœ°åŒº (è´§å¸)`ï¼šä¾‹å¦‚ `é˜¿æ‹‰ä¼¯è”åˆé…‹é•¿å›½ (AED)` / `é˜¿è”é…‹ï¼ˆAEDï¼‰` / `é˜¿è”é…‹-AED` / `é˜¿è”é…‹ AED`  
- `æ€»æ¬ æ¬¾`ï¼ˆæœ¬å¸ï¼‰ã€`æ”¶å…¥.1`ï¼ˆUSDï¼‰ã€`è°ƒæ•´`ï¼ˆæœ¬å¸ï¼Œå¯ç©ºï¼‰ã€`é¢„æ‰£ç¨`ï¼ˆæœ¬å¸ï¼Œå¯ç©ºï¼‰ã€`æ±‡ç‡`ï¼ˆUSD/æœ¬å¸ï¼Œ**ç›´æ¥ä½¿ç”¨**ï¼‰

**â‘¡ äº¤æ˜“è¡¨ï¼ˆCSV/XLSXï¼‰**ï¼š`Extended Partner Share`ã€`Partner Share Currency`ã€`SKU`  
**â‘¢ æ˜ å°„è¡¨ï¼ˆXLSXï¼‰**ï¼š`é¡¹ç›®`ã€`SKU`ï¼ˆSKU å¯æ¢è¡Œå¤šå€¼ï¼‰

**è§„åˆ™**  
- ä»…åœ¨**æœ‰æ•ˆæ•°æ®è¡Œ**ä¸Šè§£æå¸ç§ä¸åšç»Ÿè®¡ï¼ˆæ’é™¤æ ‡é¢˜/å°è®¡/ç©ºè¡Œï¼‰  
- åŒä¸€å¸ç§å¤šè¡Œæ—¶ï¼Œ`æ±‡ç‡`å–**ä¸­ä½æ•°**ï¼›(è°ƒæ•´+é¢„æ‰£ç¨)Ã—æ±‡ç‡â†’USD åæŒ‰äº¤æ˜“ USD å æ¯”åˆ†æ‘Š  
- äº¤æ˜“æœ¬å¸ Ã—æ±‡ç‡ â†’ USDï¼›`âˆ‘å‡€é¢ â‰ˆ âˆ‘è´¢æŠ¥(æ”¶å…¥.1)`ï¼ˆå®¹å·® 0.5 USDï¼‰
""")

# ---------- é€šç”¨å·¥å…· ----------
def _read_any(uploaded, header=0):
    name = uploaded.name.lower()
    if name.endswith(".csv"):
        return pd.read_csv(uploaded, header=header, engine="python", on_bad_lines="skip")
    elif name.endswith((".xlsx", ".xls")):
        return pd.read_excel(uploaded, header=header, engine="openpyxl")
    else:
        raise ValueError("ä»…æ”¯æŒ CSV æˆ– Excel æ–‡ä»¶")

def _num(s: pd.Series) -> pd.Series:
    t = s.astype(str).str.replace(",", "", regex=False).str.replace(r"[^\d\.\-\+]", "", regex=True)
    return pd.to_numeric(t, errors="coerce")

# ---------- è´¢æŠ¥è¯»å– ----------
REQ_REPORT = ["å›½å®¶æˆ–åœ°åŒº (è´§å¸)", "æ€»æ¬ æ¬¾", "æ”¶å…¥.1", "æ±‡ç‡"]
OPT_REPORT = ["è°ƒæ•´", "é¢„æ‰£ç¨"]

# è°¨æ…å›é€€ï¼ˆç»ä¸ä½¿ç”¨â€œé“¶è¡Œè´¦æˆ·å¸ç§â€è¿™ç§å¸¸ä¸ºå•å€¼çš„åˆ—ï¼‰
_CCY_FALLBACK_COLS = ["å¸ç§", "è´§å¸", "Currency"]

def _extract_currency_on_valid(df: pd.DataFrame) -> pd.Series:
    """åªåœ¨æœ‰æ•ˆæ•°æ®è¡Œä¸Šè§£æå¸ç§ï¼Œå¹¶å¯¹å°‘é‡ç¼ºå¤±è¡Œè¿›è¡Œå¿½ç•¥å¤„ç†"""
    s = df["å›½å®¶æˆ–åœ°åŒº (è´§å¸)"].astype(str)

    # 1) æ‹¬å·ä¸­çš„ 3 ä½ä»£ç ï¼šå…¨/åŠè§’éƒ½æ”¯æŒ
    pat_paren = re.compile(r"[ï¼ˆ(]\s*([A-Za-z]{3})\s*[ï¼‰)]")
    c_paren = s.str.extract(pat_paren, expand=False)

    # 2) æœ«å°¾è¿æ¥ç¬¦/ç©ºæ ¼/æ–œæ åçš„ 3 ä½ä»£ç ï¼ˆå¦‚ '- AED'ã€'/AED'ã€' AED'ï¼‰
    c_tail = s.where(c_paren.notna(), s).str.extract(r"(?:-|/|\s)([A-Za-z]{3})\s*$", expand=False)

    # 3) å…¨æ–‡ä»»æ„ 3 ä½å¤§å†™ä»£ç ï¼ˆæœ€åå…œåº•ï¼‰
    c_any = s.where(c_paren.notna() | c_tail.notna(), s).str.extract(r"\b([A-Z]{3})\b", expand=False)

    cur = c_paren.fillna(c_tail).fillna(c_any).astype(str).str.upper().replace("NAN", np.nan)

    # åªåœ¨â€œæœ‰æ•ˆè¡Œâ€ä¸Šè¯„ä¼°ç¼ºå¤±ç‡
    valid_mask = (
        df["æ€»æ¬ æ¬¾"].notna() |
        df["æ”¶å…¥.1"].notna() |
        df["æ±‡ç‡"].notna()
    )
    valid_cnt = valid_mask.sum()
    if valid_cnt == 0:
        raise ValueError("è´¢æŠ¥æ²¡æœ‰æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè¯·æ£€æŸ¥è¡¨å¤´æ˜¯å¦åœ¨ç¬¬3è¡Œã€æ•°å€¼åˆ—æ˜¯å¦ä¸ºç©ºï¼‰")

    # è°¨æ…å›é€€ï¼šä»…å½“æœ‰æ•ˆè¡Œç¼ºå¤±ç‡ä»é«˜æ—¶ï¼Œä¸”å›é€€åˆ—ä¸æ˜¯å•ä¸€å¸¸é‡æ‰ä½¿ç”¨
    miss_ratio = cur[valid_mask].isna().mean()
    if miss_ratio > 0.2:
        for col in _CCY_FALLBACK_COLS:
            if col in df.columns:
                alt_raw = df[col].astype(str)
                alt = alt_raw.str.extract(r"\b([A-Za-z]{3})\b", expand=False).str.upper()
                uniq = alt[valid_mask].dropna().unique()
                if len(uniq) <= 1:
                    continue
                cur = cur.fillna(alt)

    # ä»æœ‰æå°‘æ•°æœ‰æ•ˆè¡Œæœªèƒ½è¯†åˆ«ï¼šç›´æ¥å¿½ç•¥è¿™äº›è¡Œå¹¶æç¤º
    still_nan = cur[valid_mask].isna()
    miss_rows = int(still_nan.sum())
    if miss_rows > 0:
        bad_samples = s[valid_mask & still_nan].head(6).tolist()
        st.warning(f"ä»¥ä¸‹æœ‰æ•ˆè¡Œæ— æ³•æå–å¸ç§ï¼Œå·²è‡ªåŠ¨å¿½ç•¥ {miss_rows} è¡Œï¼ˆç¤ºä¾‹ï¼š{bad_samples}ï¼‰")
        # å¯¹è¿™äº›è¡Œç½®ç©ºå³å¯ï¼Œåç»­ä¼šåœ¨ groupby å‰ä¸¢å¼ƒ Currency ä¸º NaN çš„è¡Œ
    return cur

def read_report_final(uploaded):
    # è¡¨å¤´=ç¬¬3è¡Œ
    df = _read_any(uploaded, header=2)
    df = df[[c for c in df.columns if not str(c).startswith("Unnamed")]]
    df.columns = [str(c).strip() for c in df.columns]

    # å¿…éœ€åˆ—æ£€æŸ¥
    missing = [c for c in REQ_REPORT if c not in df.columns]
    if missing:
        raise ValueError(f"è´¢æŠ¥ç¼ºå°‘å¿…éœ€åˆ—ï¼š{missing}")

    # æ•°å€¼åŒ–
    for c in REQ_REPORT + OPT_REPORT:
        if c in df.columns:
            df[c] = _num(df[c])
        else:
            df[c] = np.nan

    # å¸ç§è§£æï¼ˆä»…çœ‹æœ‰æ•ˆè¡Œã€å¯¹å°‘æ•°æ— æ³•è¯†åˆ«çš„è¡Œç›´æ¥å¿½ç•¥ï¼‰
    df["Currency"] = _extract_currency_on_valid(df)

    # ä»…ä¿ç•™ Currency éç©ºçš„æœ‰æ•ˆç»Ÿè®¡è¡Œ
    stat = df.loc[df["Currency"].notna() & (
        df["æ€»æ¬ æ¬¾"].notna() | df["æ”¶å…¥.1"].notna() | df["æ±‡ç‡"].notna()
    )].copy()

    if stat.empty:
        raise ValueError("è´¢æŠ¥æœ‰æ•ˆç»Ÿè®¡è¡Œä¸ºç©ºï¼ˆå¯èƒ½å…¨éƒ¨ä¸ºæ ‡é¢˜/åˆè®¡æˆ–å¸ç§åˆ—å®Œå…¨ç¼ºå¤±ï¼‰")

    grp = stat.groupby("Currency", dropna=False).agg(
        local_sum=("æ€»æ¬ æ¬¾", "sum"),
        usd_sum=("æ”¶å…¥.1", "sum"),
        adj_sum=("è°ƒæ•´", "sum"),
        wht_sum=("é¢„æ‰£ç¨", "sum"),
        rate_median=("æ±‡ç‡", "median"),
        rate_min=("æ±‡ç‡", "min"),
        rate_max=("æ±‡ç‡", "max"),
        rows=("æ±‡ç‡", "size"),
    ).reset_index()

    grp["æ±‡ç‡(USD/æœ¬å¸)"] = grp["rate_median"]
    grp["AdjTaxUSD"] = (grp["adj_sum"].fillna(0) + grp["wht_sum"].fillna(0)) * grp["æ±‡ç‡(USD/æœ¬å¸)"]

    audit = grp.rename(columns={
        "local_sum": "æœ¬å¸æ€»æ¬ æ¬¾",
        "usd_sum": "ç¾å…ƒæ”¶å…¥åˆè®¡(æ”¶å…¥.1)",
        "adj_sum": "è°ƒæ•´(æœ¬å¸)åˆè®¡",
        "wht_sum": "é¢„æ‰£ç¨(æœ¬å¸)åˆè®¡",
    })

    # è‹¥åªè¯†åˆ«å‡º 1 ä¸ªå¸ç§ï¼Œä¹Ÿå…è®¸ç»§ç»­ï¼ˆä½†ä¼šåœ¨äº¤æ˜“è¦†ç›–æ ¡éªŒæ—¶æŠ¥é”™æ›´æ˜ç¡®ï¼‰
    rates = dict(zip(audit["Currency"], audit["æ±‡ç‡(USD/æœ¬å¸)"]))
    report_total_usd = float(audit["ç¾å…ƒæ”¶å…¥åˆè®¡(æ”¶å…¥.1)"].sum())
    total_adj_usd = float(audit["AdjTaxUSD"].sum())

    inconsistent = audit.loc[
        audit["rate_min"].round(8) != audit["rate_max"].round(8),
        ["Currency","rate_min","rate_max","rows"]
    ]
    if len(inconsistent):
        st.warning("ä»¥ä¸‹å¸ç§çš„è´¢æŠ¥`æ±‡ç‡`å­˜åœ¨å·®å¼‚ï¼Œ**å·²ä½¿ç”¨ä¸­ä½æ•°**ï¼š")
        st.dataframe(inconsistent)

    st.info(f"è´¢æŠ¥è¯†åˆ«åˆ°çš„å¸ç§ï¼š{sorted(audit['Currency'].dropna().unique().tolist())}")

    return audit, rates, total_adj_usd, report_total_usd

# ---------- äº¤æ˜“ ----------
REQ_TX = ["Extended Partner Share", "Partner Share Currency", "SKU"]

def read_tx_final(uploaded, amount_unit: str):
    df = _read_any(uploaded, header=0)
    df.columns = [str(c).strip() for c in df.columns]

    missing = [c for c in REQ_TX if c not in df.columns]
    if missing:
        raise ValueError(f"äº¤æ˜“è¡¨ç¼ºå°‘å¿…éœ€åˆ—ï¼š{missing}")

    df["Extended Partner Share"] = _num(df["Extended Partner Share"])
    if amount_unit == "åˆ†(Ã·100)":
        df["Extended Partner Share"] = df["Extended Partner Share"] / 100.0
    elif amount_unit == "å˜(Ã·1000)":
        df["Extended Partner Share"] = df["Extended Partner Share"] / 1000.0

    df["Partner Share Currency"] = df["Partner Share Currency"].astype(str).str.strip().str.upper()
    return df[REQ_TX].copy()

# ---------- æ˜ å°„ ----------
REQ_MAP = ["é¡¹ç›®","SKU"]

def read_map_final(uploaded):
    mp = _read_any(uploaded, header=0)
    mp.columns = [str(c).strip() for c in mp.columns]
    missing = [c for c in REQ_MAP if c not in mp.columns]
    if missing:
        raise ValueError(f"æ˜ å°„è¡¨ç¼ºå°‘å¿…éœ€åˆ—ï¼š{missing}")
    mp = mp.assign(SKU=mp["SKU"].astype(str).str.split("\n")).explode("SKU")
    mp["SKU"] = mp["SKU"].str.strip()
    mp = mp[mp["SKU"]!=""]
    return mp[["é¡¹ç›®","SKU"]].copy()

# ---------- UI ----------
c1, c2, c3 = st.columns(3)
with c1:
    tx_file = st.file_uploader("â‘  äº¤æ˜“è¡¨ï¼ˆCSV/XLSXï¼‰", type=["csv","xlsx","xls"])
with c2:
    rp_file = st.file_uploader("â‘¡ è´¢æŠ¥ï¼ˆCSV/XLSXï½œè¡¨å¤´=ç¬¬3è¡Œï¼‰", type=["csv","xlsx","xls"])
with c3:
    mp_file = st.file_uploader("â‘¢ é¡¹ç›®â€“SKUï¼ˆXLSXï¼‰", type=["xlsx","xls"])

amount_unit = st.radio("äº¤æ˜“é‡‘é¢å•ä½", ["å…ƒ(ä¸ç”¨æ¢)", "åˆ†(Ã·100)", "å˜(Ã·1000)"], index=0, horizontal=True)
strict_check = st.checkbox("ä¸¥æ ¼å¯¹è´¦ï¼š|âˆ‘å‡€é¢ âˆ’ âˆ‘è´¢æŠ¥USD| â‰¤ 0.5", value=True)

if st.button("ğŸš€ å¼€å§‹è®¡ç®—"):
    try:
        # 1) è´¢æŠ¥
        if not rp_file:
            raise ValueError("æœªä¸Šä¼ è´¢æŠ¥")
        audit, rates, total_adj_usd, report_total_usd = read_report_final(rp_file)

        # 2) äº¤æ˜“
        if not tx_file:
            raise ValueError("æœªä¸Šä¼ äº¤æ˜“è¡¨")
        tx = read_tx_final(tx_file, amount_unit)

        # äº¤æ˜“å¸ç§è¦†ç›–æ ¡éªŒ
        tx_ccy = set(tx["Partner Share Currency"].dropna().unique())
        missing_ccy = sorted(tx_ccy - set(rates.keys()))
        if missing_ccy:
            raise ValueError(f"äº¤æ˜“è¡¨å‡ºç°è´¢æŠ¥æœªè¦†ç›–çš„å¸ç§ï¼š{missing_ccy}")

        # 3) äº¤æ˜“è®¡ç®—
        tx["rate_usd_per_local"] = tx["Partner Share Currency"].map(rates).astype(float)
        tx["Extended Partner Share USD"] = tx["Extended Partner Share"] * tx["rate_usd_per_local"]

        tx_total_usd = float(tx["Extended Partner Share USD"].sum())
        if not np.isfinite(tx_total_usd) or tx_total_usd == 0:
            raise ValueError("äº¤æ˜“ USD åˆè®¡ä¸º 0ï¼Œè¯·æ£€æŸ¥é‡‘é¢åˆ—æˆ–å•ä½ã€‚")

        tx["Cost Allocation (USD)"] = tx["Extended Partner Share USD"] / tx_total_usd * total_adj_usd
        tx["Net Partner Share (USD)"] = tx["Extended Partner Share USD"] + tx["Cost Allocation (USD)"]

        # 4) æ˜ å°„ä¸æ±‡æ€»
        if not mp_file:
            raise ValueError("æœªä¸Šä¼ é¡¹ç›®â€“SKU æ˜ å°„")
        mp = read_map_final(mp_file)
        sku2proj = dict(zip(mp["SKU"], mp["é¡¹ç›®"]))
        tx["é¡¹ç›®"] = tx["SKU"].astype(str).map(sku2proj)

        summary = tx.groupby("é¡¹ç›®", dropna=False)[
            ["Extended Partner Share USD","Cost Allocation (USD)","Net Partner Share (USD)"]
        ].sum().reset_index()

        net_total = float(tx["Net Partner Share (USD)"].sum())
        diff = net_total - report_total_usd
        if strict_check and abs(diff) > 0.5:
            raise ValueError(f"å¯¹è´¦å¤±è´¥ï¼šäº¤æ˜“å‡€é¢ {net_total:,.2f} USD ä¸è´¢æŠ¥ {report_total_usd:,.2f} USD å·®å¼‚ {diff:,.2f} USD")

        # 5) è¾“å‡º
        st.success("âœ… è®¡ç®—å®Œæˆ")
        st.markdown(f"- è´¢æŠ¥ç¾å…ƒæ”¶å…¥åˆè®¡ï¼ˆâˆ‘æ”¶å…¥.1ï¼‰ï¼š**{report_total_usd:,.2f} USD**")
        st.markdown(f"- åˆ†æ‘Šæ€»é¢ï¼ˆè°ƒæ•´+é¢„æ‰£ç¨ â†’ USDï¼‰ï¼š**{total_adj_usd:,.2f} USD**")
        st.markdown(f"- äº¤æ˜“æ¯›æ”¶å…¥ USD åˆè®¡ï¼š**{tx_total_usd:,.2f} USD**")
        st.markdown(f"- äº¤æ˜“å‡€é¢ USD åˆè®¡ï¼š**{net_total:,.2f} USD**ï¼ˆå·®å¼‚ {diff:,.2f} USDï¼‰")

        st.download_button("â¬‡ï¸ å®¡è®¡è¡¨ (CSV)",
            data=audit.to_csv(index=False).encode("utf-8-sig"),
            file_name="financial_report_audit.csv", mime="text/csv")
        st.download_button("â¬‡ï¸ é€å•ç»“æœ (CSV)",
            data=tx.to_csv(index=False).encode("utf-8-sig"),
            file_name="transactions_usd.csv", mime="text/csv")
        st.download_button("â¬‡ï¸ é¡¹ç›®æ±‡æ€» (CSV)",
            data=summary.to_csv(index=False).encode("utf-8-sig"),
            file_name="project_summary.csv", mime="text/csv")

        with st.expander("é¢„è§ˆï¼šè´¢æŠ¥å®¡è®¡", expanded=False):
            st.dataframe(audit)
        with st.expander("é¢„è§ˆï¼šé€å•ç»“æœ", expanded=False):
            st.dataframe(tx.head(200))
        with st.expander("é¢„è§ˆï¼šé¡¹ç›®æ±‡æ€»", expanded=True):
            st.dataframe(summary)

    except Exception as e:
        st.error(f"âš ï¸ å‡ºé”™ï¼š{e}")
        st.exception(e)
