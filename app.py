# app.py â€” IAP ORCAT Onlineï¼ˆçŸ©é˜µè´¢æŠ¥ä¸“ç”¨ï¼Œå«å»é‡ä¸å‘é‡åŒ–ä¿®å¤ï¼‰
import re
import numpy as np
import pandas as pd
import streamlit as st

st.set_page_config(page_title="IAP â€” ORCAT Online (Matrix Edition)", page_icon="ğŸ’¼", layout="wide")
st.title("ğŸ’¼ IAP â€” ORCAT Onlineï¼ˆçŸ©é˜µè´¢æŠ¥ä¸“ç”¨ï¼‰")

with st.expander("ä½¿ç”¨è¯´æ˜", expanded=False):
    st.markdown("""
**è¯·ä¸Šä¼  3 ä¸ªæ–‡ä»¶ï¼š**  
1) **äº¤æ˜“è¡¨**ï¼ˆCSV/XLSXï¼‰ï¼šåŒ…å« é‡‘é¢ï¼ˆæœ¬å¸ï¼‰ã€å¸ç§ã€SKU  
2) **Apple è´¢æŠ¥ï¼ˆçŸ©é˜µæ ¼å¼ï¼‰**ï¼ˆCSV/XLSXï¼‰ï¼šç¬¬ä¸€åˆ—ä¸ºâ€œå›½å®¶æˆ–åœ°åŒº (è´§å¸)â€ï¼Œå³ä¾§ä¸ºå„å¸ç§åˆ—ï¼›ä¸‹æ–¹å¤šè¡Œæ˜¯æŒ‡æ ‡ï¼ˆæ€»æ¬ æ¬¾/æ”¶å…¥(ç¾å…ƒ)æˆ–æ”¶å…¥.1/è°ƒæ•´/é¢„æ‰£ç¨/æ±‡ç‡ï¼‰  
3) **é¡¹ç›®-SKU æ˜ å°„**ï¼ˆXLSXï¼‰ï¼šåˆ— `é¡¹ç›®`ã€`SKU`ï¼ˆSKU å¯æ¢è¡Œå¤šä¸ªï¼‰

**è®¡ç®—æ¦‚è§ˆï¼š**  
- ä»çŸ©é˜µè´¢æŠ¥æŠ½å–æ¯å¸ç§ï¼š`æ€»æ¬ æ¬¾`ã€`æ”¶å…¥.1(USD)`ã€`è°ƒæ•´`ã€`é¢„æ‰£ç¨`ã€`æ±‡ç‡(æœ¬å¸/ç¾å…ƒ)`ï¼›è‹¥ç¼ºâ€œæ±‡ç‡â€åˆ™ç”¨ `æ€»æ¬ æ¬¾/æ”¶å…¥.1` æ¨å¯¼  
- åˆ†æ‘Šç¾å…ƒï¼š`(è°ƒæ•´+é¢„æ‰£ç¨)/æ±‡ç‡` çš„æ€»é¢æŒ‰äº¤æ˜“ USD å æ¯”åˆ†æ‘Šåˆ°æ¯æ¡è®°å½•  
- ç»“æœè¾“å‡ºï¼šé€å•ï¼ˆæ¯›æ”¶å…¥USDã€åˆ†æ‘Šã€å‡€é¢ã€é¡¹ç›®ï¼‰ä¸é¡¹ç›®æ±‡æ€»ï¼Œå¯ä¸‹è½½
""")

# ------------------ åŸºç¡€è¯»å– ------------------
def _read_any(uploaded, header=None):
    name = uploaded.name.lower()
    if name.endswith(".csv"):
        return pd.read_csv(uploaded, header=header, engine="python", on_bad_lines="skip")
    elif name.endswith((".xlsx", ".xls")):
        return pd.read_excel(uploaded, header=header, engine="openpyxl")
    else:
        raise ValueError("ä»…æ”¯æŒ CSV æˆ– Excel (xlsx/xls) æ–‡ä»¶")

def _norm_colkey(s: str) -> str:
    s = str(s).strip().lower()
    s = re.sub(r'[\s\-\_\/\.\(\):ï¼Œ,]+', '', s)
    return s

# ------------------ çŸ©é˜µè´¢æŠ¥è§£æ ------------------
def find_header_index(raw: pd.DataFrame) -> int:
    """å®šä½â€˜å›½å®¶æˆ–åœ°åŒº (è´§å¸)â€™è¿™ä¸€è¡Œçš„è¡Œå·ï¼ˆæ— è¡¨å¤´ DataFrameï¼‰ã€‚"""
    col0 = raw.iloc[:, 0].astype(str).str.replace("\u3000", " ").str.strip()
    idx = col0[col0 == "å›½å®¶æˆ–åœ°åŒº (è´§å¸)"].index.tolist()
    if idx:
        return idx[0]
    # å®½æ¾åŒ¹é…
    pattern = re.compile(r"å›½å®¶æˆ–åœ°åŒº\s*[\(\ï¼ˆ]è´§å¸[\)\ï¼‰]")
    idx = col0[col0.str.contains(pattern)].index.tolist()
    if idx:
        return idx[0]
    # å†å®½ï¼šåŒ…å« (XXX) çš„è¡Œ
    idx = col0[col0.str.contains(r"\([A-Za-z]{3}\)")].index.tolist()
    if idx:
        return idx[0]
    raise ValueError("æœªæ‰¾åˆ°è¡¨å¤´è¡Œï¼šéœ€è¦ç¬¬ä¸€åˆ—ä¸ºâ€œå›½å®¶æˆ–åœ°åŒº (è´§å¸)â€çš„ä¸€è¡Œã€‚")

def _normalize_metric_name(s: str) -> str:
    s2 = re.sub(r"\s+", "", str(s))
    # å¸¸è§åˆ«åï¼šæ”¶å…¥(ç¾å…ƒ) â†’ æ”¶å…¥.1
    s2 = s2.replace("æ”¶å…¥ï¼ˆç¾å…ƒï¼‰", "æ”¶å…¥.1").replace("æ”¶å…¥(ç¾å…ƒ)", "æ”¶å…¥.1")
    return s2

def parse_matrix_report(uploaded) -> pd.DataFrame:
    """
    å°†â€œå›½å®¶æˆ–åœ°åŒº (è´§å¸)â€æ¨ªå‘çŸ©é˜µè´¢æŠ¥æ ‡å‡†åŒ–ä¸ºé•¿è¡¨ï¼š
    è¿”å›åˆ—ï¼šCurrency, æ€»æ¬ æ¬¾, æ”¶å…¥.1(USD), æ±‡ç‡(æœ¬å¸/ç¾å…ƒ), è°ƒæ•´, é¢„æ‰£ç¨, AdjTaxUSD
    """
    raw = _read_any(uploaded, header=None)
    hdr = find_header_index(raw)

    headers = raw.iloc[hdr, :].tolist()                  # ç¬¬ä¸€è¡Œï¼šå›½å®¶(è´§å¸) + å„å¸ç§åˆ—å
    data_block = raw.iloc[hdr + 1 :, :].copy()
    data_block.columns = [f"col{i}" for i in range(data_block.shape[1])]
    metric_names = data_block["col0"].astype(str).str.strip()

    wanted = {"æ€»æ¬ æ¬¾", "æ”¶å…¥.1", "æ”¶å…¥", "è°ƒæ•´", "é¢„æ‰£ç¨", "æ±‡ç‡"}

    # å¸ç§åˆ—ï¼ˆè·³è¿‡ç¬¬ä¸€æ ¼æ ‡é¢˜ï¼‰
    currencies_headers = []
    for h in headers[1:]:
        hs = str(h).strip()
        if hs and hs.lower() != "nan":
            currencies_headers.append(hs)

    # é€å¸ç§æŠ½å–æŒ‡æ ‡
    records = []
    for j, cur in enumerate(currencies_headers, start=1):
        colname = f"col{j}"
        values = {}
        for idx, s in enumerate(metric_names):
            nm = _normalize_metric_name(s)
            if nm in wanted:
                try:
                    values[nm] = pd.to_numeric(data_block.iloc[idx][colname], errors="coerce")
                except Exception:
                    values[nm] = pd.NA

        usd_rev = values.get("æ”¶å…¥.1", pd.NA)
        if (pd.isna(usd_rev) or usd_rev is pd.NA) and ("æ”¶å…¥" in values):
            usd_rev = values.get("æ”¶å…¥", pd.NA)

        records.append({
            "CurrencyHeader": cur,
            "æ€»æ¬ æ¬¾": values.get("æ€»æ¬ æ¬¾", pd.NA),
            "æ”¶å…¥.1": usd_rev,      # è§†ä¸ºç¾å…ƒæ”¶å…¥
            "è°ƒæ•´": values.get("è°ƒæ•´", 0),
            "é¢„æ‰£ç¨": values.get("é¢„æ‰£ç¨", 0),
            "æ±‡ç‡": values.get("æ±‡ç‡", pd.NA),  # è‹¥ç¼ºåˆ™åç»­ç”¨ æ€»æ¬ æ¬¾/æ”¶å…¥.1 æ¨å¯¼
        })

    tidy = pd.DataFrame(records)

    # â€”â€” ä¿®å¤ç‚¹ 1ï¼šå»é‡åˆ—åï¼Œé¿å…é‡å¤åˆ—åå¼•å‘â€œå¤šåˆ—èµ‹å•åˆ—â€é”™è¯¯
    tidy = tidy.loc[:, ~tidy.columns.duplicated(keep="first")]

    # æå– 3 ä½å¸ç§ä»£ç 
    tidy["Currency"] = tidy["CurrencyHeader"].astype(str).str.extract(r"\(([A-Za-z]{3})\)").iloc[:, 0]
    tidy = tidy.dropna(subset=["Currency"]).reset_index(drop=True)

    # æ•°å€¼åŒ–
    for c in ["æ€»æ¬ æ¬¾", "æ”¶å…¥.1", "è°ƒæ•´", "é¢„æ‰£ç¨", "æ±‡ç‡"]:
        if c in tidy.columns:
            tidy[c] = pd.to_numeric(tidy[c], errors="coerce")

    # â€”â€” ä¿®å¤ç‚¹ 2ï¼šå‘é‡åŒ–æ¨å¯¼æ±‡ç‡ï¼Œé¿å… apply è¿”å› DataFrame
    income = tidy["æ”¶å…¥.1"].fillna(0).to_numpy(dtype="float64")
    base_local = tidy["æ€»æ¬ æ¬¾"].fillna(0).to_numpy(dtype="float64")
    rate_calc = np.where(income != 0, base_local / income, np.nan)

    if "æ±‡ç‡" in tidy.columns:
        rate_given = tidy["æ±‡ç‡"].to_numpy(dtype="float64")
    else:
        rate_given = np.full(len(tidy), np.nan, dtype="float64")

    rate = np.where(np.isnan(rate_given), rate_calc, rate_given)
    tidy["rate"] = rate

    # â€”â€” ä¿®å¤ç‚¹ 3ï¼šåˆ†æ‘Šç¾å…ƒï¼ˆé¿å…é™¤ 0ï¼‰
    adj = tidy["è°ƒæ•´"].fillna(0).to_numpy(dtype="float64")
    wht = tidy["é¢„æ‰£ç¨"].fillna(0).to_numpy(dtype="float64")
    denom = rate.copy()
    denom[denom == 0] = np.nan
    adj_usd = (adj + wht) / denom
    tidy["AdjTaxUSD"] = pd.to_numeric(adj_usd, errors="coerce")

    # è¾“å‡ºåˆ—
    out = tidy[["Currency", "æ€»æ¬ æ¬¾", "æ”¶å…¥.1", "rate", "è°ƒæ•´", "é¢„æ‰£ç¨", "AdjTaxUSD"]].rename(
        columns={"æ”¶å…¥.1": "æ”¶å…¥.1(USD)", "rate": "æ±‡ç‡(æœ¬å¸/ç¾å…ƒ)"}
    )

    # è°ƒè¯•å±•ç¤º
    st.subheader("ğŸ“Š è´¢æŠ¥ï¼ˆçŸ©é˜µâ†’æ ‡å‡†åŒ–ï¼‰é¢„è§ˆ")
    st.write("è¯†åˆ«çš„å¸ç§åˆ—æ•°ï¼š", len(out))
    st.dataframe(out.head(20))
    return out

def build_rates_and_totals(cleaned_report: pd.DataFrame):
    rates = dict(zip(cleaned_report["Currency"], cleaned_report["æ±‡ç‡(æœ¬å¸/ç¾å…ƒ)"]))
    total_adj_usd = float(pd.to_numeric(cleaned_report["AdjTaxUSD"], errors="coerce").sum())
    report_total_usd = float(pd.to_numeric(cleaned_report["æ”¶å…¥.1(USD)"], errors="coerce").sum())
    return rates, total_adj_usd, report_total_usd

# ------------------ äº¤æ˜“è¡¨ï¼ˆè‡ªåŠ¨è¯†åˆ« + æ‰‹åŠ¨æ˜ å°„å…œåº•ï¼‰ ------------------
def _auto_guess_tx_cols(cols):
    norm_map = {c: _norm_colkey(c) for c in cols}

    # é‡‘é¢åˆ—ï¼ˆä¼˜å…ˆ extended partner share / proceeds / amountï¼‰
    eps = None
    for c, n in norm_map.items():
        if ('extended' in n and 'partner' in n and ('share' in n or 'proceeds' in n or 'amount' in n)) \
           or ('partnershareextended' in n) \
           or (('partnershare' in n or 'partnerproceeds' in n) and ('amount' in n or 'gross' in n or 'net' in n)):
            eps = c; break
    if eps is None:
        for c, n in norm_map.items():
            if ('proceeds' in n or 'revenue' in n or 'amount' in n) and ('partner' in n or 'publisher' in n):
                eps = c; break

    # å¸ç§åˆ—
    cur = None
    for c, n in norm_map.items():
        if ('currency' in n) or ('iso' in n and 'code' in n) or n == 'currency':
            cur = c; break
    if cur is None:
        for c, n in norm_map.items():
            if n.endswith('currencycode') or n.endswith('currency'):
                cur = c; break
    if cur is None and 'Currency' in cols:
        cur = 'Currency'

    # SKU åˆ—
    sku = None
    for c, n in norm_map.items():
        if n == 'sku' or n.endswith('sku') or 'productid' in n or n == 'productid' or n == 'itemid':
            sku = c; break
    if sku is None and 'SKU' in cols:
        sku = 'SKU'

    return eps, cur, sku

def read_tx(uploaded):
    df = _read_any(uploaded)
    df.columns = [str(c).strip() for c in df.columns]
    st.subheader("ğŸ“Š äº¤æ˜“è¡¨é¢„è§ˆ")
    st.write("åˆ—åï¼š", list(df.columns))
    st.dataframe(df.head())

    eps, cur, sku = _auto_guess_tx_cols(df.columns)
    with st.expander("ğŸ›  æ‰‹åŠ¨åˆ—æ˜ å°„ï¼ˆè‡ªåŠ¨è¯†åˆ«ä¸å‡†æ—¶è¯·è°ƒæ•´ï¼‰", expanded=not (eps and cur and sku)):
        cols = list(df.columns)
        eps = st.selectbox("é‡‘é¢åˆ—ï¼ˆExtended Partner Share / Proceeds / Amountï¼‰", cols, index=(cols.index(eps) if eps in cols else 0))
        cur = st.selectbox("å¸ç§åˆ—ï¼ˆPartner Share Currency / Currencyï¼‰", cols, index=(cols.index(cur) if cur in cols else 0))
        sku = st.selectbox("SKU åˆ—ï¼ˆSKU / Product ID / Item IDï¼‰", cols, index=(cols.index(sku) if sku in cols else 0))

    rename_map = {eps: "Extended Partner Share", cur: "Partner Share Currency", sku: "SKU"}
    df = df.rename(columns=rename_map)

    need = {"Extended Partner Share", "Partner Share Currency", "SKU"}
    missing = need - set(df.columns)
    if missing:
        raise ValueError(f"âŒ äº¤æ˜“è¡¨ä»ç¼ºå°‘åˆ—ï¼š{missing}ï¼›è¯·åœ¨â€œæ‰‹åŠ¨åˆ—æ˜ å°„â€é‡Œé€‰æ‹©æ­£ç¡®çš„åˆ—ã€‚")

    # é‡‘é¢å»é€—å· â†’ æ•°å€¼
    df["Extended Partner Share"] = df["Extended Partner Share"].astype(str).str.replace(",", "", regex=False)
    df["Extended Partner Share"] = pd.to_numeric(df["Extended Partner Share"], errors="coerce")

    return df

# ------------------ æ˜ å°„è¡¨ ------------------
def read_map(uploaded):
    df = pd.read_excel(uploaded, engine="openpyxl", dtype=str)
    df.columns = [str(c).strip() for c in df.columns]
    st.subheader("ğŸ“Š æ˜ å°„è¡¨é¢„è§ˆ")
    st.write("åˆ—åï¼š", list(df.columns))
    st.dataframe(df.head())
    if not {"é¡¹ç›®", "SKU"}.issubset(df.columns):
        raise ValueError("âŒ æ˜ å°„è¡¨ç¼ºå°‘åˆ— `é¡¹ç›®` æˆ– `SKU`")
    df = df.assign(SKU=df["SKU"].astype(str).str.split("\n")).explode("SKU")
    df["SKU"] = df["SKU"].str.strip()
    return df[df["SKU"] != ""][["é¡¹ç›®", "SKU"]]

# ------------------ ä¸Šä¼ åŒº ------------------
c1, c2, c3 = st.columns(3)
with c1: tx = st.file_uploader("â‘  äº¤æ˜“è¡¨ï¼ˆCSV/XLSXï¼‰", type=["csv", "xlsx", "xls"], key="tx")
with c2: rp = st.file_uploader("â‘¡ Apple è´¢æŠ¥ï¼ˆçŸ©é˜µæ ¼å¼ï¼ŒCSV/XLSXï¼‰", type=["csv", "xlsx", "xls"], key="rp")
with c3: mp = st.file_uploader("â‘¢ é¡¹ç›®-SKUï¼ˆXLSXï¼‰", type=["xlsx", "xls"], key="mp")

if st.button("ğŸš€ å¼€å§‹è®¡ç®—ï¼ˆçŸ©é˜µè´¢æŠ¥ä¸“ç”¨ï¼‰"):
    if not (tx and rp and mp):
        st.error("âŒ è¯·å…ˆä¸Šä¼ ä¸‰ä»½æ–‡ä»¶")
    else:
        try:
            # 1) è´¢æŠ¥ â†’ æ ‡å‡†åŒ–
            cleaned_report = parse_matrix_report(rp)
            rates, total_adj_usd, report_total_usd = build_rates_and_totals(cleaned_report)

            # 2) äº¤æ˜“ + æ˜ å°„
            txdf = read_tx(tx)
            mpdf = read_map(mp)
            sku2proj = dict(zip(mpdf["SKU"], mpdf["é¡¹ç›®"]))

            # 3) äº¤æ˜“æ¢ç®— USD + åˆ†æ‘Š
            txdf["Extended Partner Share USD"] = txdf.apply(
                lambda r: (r["Extended Partner Share"] / rates.get(str(r["Partner Share Currency"]), 1))
                          if pd.notnull(r["Extended Partner Share"]) else None,
                axis=1
            )
            total_usd = pd.to_numeric(txdf["Extended Partner Share USD"], errors="coerce").sum(min_count=1)
            if not pd.notnull(total_usd) or total_usd == 0:
                st.error("âŒ äº¤æ˜“ USD æ±‡æ€»ä¸º 0ï¼Œå¯èƒ½å¸ç§ä¸åŒ¹é…æˆ–é‡‘é¢åˆ—ä¸ºç©º")
                st.stop()

            txdf["Cost Allocation (USD)"] = txdf["Extended Partner Share USD"] / total_usd * total_adj_usd
            txdf["Net Partner Share (USD)"] = txdf["Extended Partner Share USD"] + txdf["Cost Allocation (USD)"]
            txdf["é¡¹ç›®"] = txdf["SKU"].map(sku2proj)

            # 4) æ±‡æ€»
            summary = txdf.groupby("é¡¹ç›®", dropna=False)[
                ["Extended Partner Share USD", "Cost Allocation (USD)", "Net Partner Share (USD)"]
            ].sum().reset_index()
            total_row = {
                "é¡¹ç›®": "__TOTAL__",
                "Extended Partner Share USD": float(summary["Extended Partner Share USD"].sum()),
                "Cost Allocation (USD)": float(summary["Cost Allocation (USD)"].sum()),
                "Net Partner Share (USD)": float(summary["Net Partner Share (USD)"].sum())
            }
            summary = pd.concat([summary, pd.DataFrame([total_row])], ignore_index=True)

            # 5) å±•ç¤º & ä¸‹è½½
            st.success("âœ… è®¡ç®—å®Œæˆ")
            st.markdown(f"- è´¢æŠ¥ç¾å…ƒæ”¶å…¥æ€»é¢ï¼ˆsum of æ”¶å…¥.1ï¼‰ï¼š**{report_total_usd:,.2f} USD**")
            st.markdown(f"- åˆ†æ‘Šæ€»é¢ï¼ˆè°ƒæ•´+é¢„æ‰£ç¨ï¼‰ï¼š**{total_adj_usd:,.2f} USD**")
            st.markdown(f"- äº¤æ˜“æ¯›æ”¶å…¥ USD åˆè®¡ï¼š**{float(total_usd):,.2f} USD**")

            st.download_button("â¬‡ï¸ ä¸‹è½½ï¼šé€å•ç»“æœ CSV",
                               data=txdf.to_csv(index=False).encode("utf-8-sig"),
                               file_name="transactions_usd_net_project.csv", mime="text/csv")
            st.download_button("â¬‡ï¸ ä¸‹è½½ï¼šé¡¹ç›®æ±‡æ€» CSV",
                               data=summary.to_csv(index=False).encode("utf-8-sig"),
                               file_name="project_summary.csv", mime="text/csv")

            with st.expander("é¢„è§ˆï¼šè´¢æŠ¥ï¼ˆæ ‡å‡†åŒ–åï¼‰", expanded=False):
                st.dataframe(cleaned_report)
            with st.expander("é¢„è§ˆï¼šé€å•ç»“æœ", expanded=False):
                st.dataframe(txdf.head(200))
            with st.expander("é¢„è§ˆï¼šé¡¹ç›®æ±‡æ€»", expanded=True):
                st.dataframe(summary)

        except Exception as e:
            st.error(f"âš ï¸ å‡ºé”™ï¼š{e}")
            st.exception(e)
