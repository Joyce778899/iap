# app.py â€” IAP ORCAT Onlineï¼ˆçŸ©é˜µè´¢æŠ¥ | USD/æœ¬å¸ | å¼ºæ ¡éªŒ + é˜²ä¸²åˆ—ï¼‰
import re
import numpy as np
import pandas as pd
import streamlit as st

st.set_page_config(page_title="IAP â€” ORCAT Online (Matrix USD/Local, Safe)", page_icon="ğŸ’¼", layout="wide")
st.title("ğŸ’¼ IAP â€” ORCAT Onlineï¼ˆçŸ©é˜µè´¢æŠ¥ | USD/æœ¬å¸ | å¼ºæ ¡éªŒï¼‰")

with st.expander("ä½¿ç”¨è¯´æ˜", expanded=False):
    st.markdown("""
**ä¸Šä¼  3 ä¸ªæ–‡ä»¶ï¼š**
1) äº¤æ˜“è¡¨ï¼ˆCSV/XLSXï¼‰ï¼šéœ€å« é‡‘é¢ï¼ˆæœ¬å¸ï¼‰ã€å¸ç§ï¼ˆå»ºè®® 3 ä½ä»£ç ï¼‰ã€SKU  
2) Apple è´¢æŠ¥ï¼ˆCSV/XLSXï¼ŒçŸ©é˜µæ ¼å¼ï¼‰ï¼š**ç¬¬ä¸‰è¡Œ**ä¸ºè¡¨å¤´ï¼ŒåŒ…å« `å›½å®¶æˆ–åœ°åŒº (è´§å¸) / æ”¶å…¥ / æ€»æ¬ æ¬¾ / æ±‡ç‡ / æ”¶å…¥.1 / é¢„æ‰£ç¨ / è°ƒæ•´` ç­‰  
3) é¡¹ç›®-SKU æ˜ å°„ï¼ˆXLSXï¼‰ï¼šåˆ— `é¡¹ç›®`ã€`SKU`ï¼ˆSKU å¯æ¢è¡Œå¤šä¸ªï¼‰

**æ ¸å¿ƒé€»è¾‘ï¼ˆä¸ä½ çš„æ¨¡æ¿åŒ¹é…ï¼‰**
- ä» `å›½å®¶æˆ–åœ°åŒº (è´§å¸)` æå–å¸ç§ï¼ˆä¸‰ä½ä»£ç ï¼‰
- å¸ç§èšåˆï¼š`æ±‡ç‡(USD/æœ¬å¸) = âˆ‘(æ”¶å…¥.1, USD) / âˆ‘(æ€»æ¬ æ¬¾, æœ¬å¸)`
- `(è°ƒæ•´+é¢„æ‰£ç¨)` æŠ˜ç¾å…ƒï¼š**ä¹˜æ³•** `(è°ƒæ•´+é¢„æ‰£ç¨) * æ±‡ç‡(USD/æœ¬å¸)`
- äº¤æ˜“ USDï¼š`Extended Partner Share * æ±‡ç‡(USD/æœ¬å¸)`ï¼ˆUSD è‡ªèº«=1ï¼‰
- åˆ†æ‘ŠæŒ‰äº¤æ˜“ USD å æ¯”ï¼›æœ€ç»ˆ**å‡€é¢åˆè®¡ â‰ˆ è´¢æŠ¥ç¾å…ƒæ”¶å…¥åˆè®¡**ï¼ˆå¯è®¾å®¹å·®ï¼‰

**é˜²å‘†/è‡ªæ£€**
- å¼ºåˆ¶å±•å¼€â€œæ‰‹åŠ¨åˆ—æ˜ å°„â€
- é‡‘é¢å•ä½é€‰æ‹©ï¼šå…ƒ/åˆ†(Ã·100)/å˜(Ã·1000)
- é‡‘é¢åˆ†å¸ƒä½“æ£€ï¼ˆp90/p99/maxï¼›ç–‘ä¼¼IDåˆ—è‡ªåŠ¨æ’é™¤ï¼‰ï¼Œå¼‚å¸¸ç›´æ¥é˜»æ–­
- å¸ç§å€¼æ ‡å‡†åŒ–ï¼ˆä¸­æ–‡å¸å/æ‹¬å·ä»£ç  â†’ 3 ä½ä»£ç ï¼‰ï¼Œå¯¹ä¸ä¸Šç›´æ¥é˜»æ–­
""")

# ---------------- åŸºç¡€è¯»å– ----------------
def _read_any(uploaded, header=None):
    name = uploaded.name.lower()
    if name.endswith(".csv"):
        return pd.read_csv(uploaded, header=header, engine="python", on_bad_lines="skip")
    elif name.endswith((".xlsx", ".xls")):
        return pd.read_excel(uploaded, header=header, engine="openpyxl")
    else:
        raise ValueError("ä»…æ”¯æŒ CSV æˆ– Excel æ–‡ä»¶")

def _norm_colkey(s: str) -> str:
    s = str(s).strip().lower()
    s = re.sub(r'[\s\-\_\/\.\(\):ï¼Œ,]+', '', s)
    return s

# ---------------- è´¢æŠ¥è§£æï¼ˆçŸ©é˜µ â†’ å¸ç§èšåˆï¼›USD/æœ¬å¸ï¼‰ ----------------
def read_report_matrix(uploaded) -> pd.DataFrame:
    # ä½ çš„è´¢æŠ¥ä¸ºç¬¬ä¸‰è¡Œ(ç´¢å¼•=2)æ˜¯è¡¨å¤´
    df = _read_any(uploaded, header=2)
    df = df[[c for c in df.columns if not str(c).startswith("Unnamed")]]
    df.columns = [str(c).strip() for c in df.columns]
    if "å›½å®¶æˆ–åœ°åŒº (è´§å¸)" not in df.columns:
        raise ValueError("è´¢æŠ¥ç¼ºå°‘åˆ—ï¼šå›½å®¶æˆ–åœ°åŒº (è´§å¸)")

    # æå–ä¸‰ä½å¸ç§ä»£ç 
    df["Currency"] = df["å›½å®¶æˆ–åœ°åŒº (è´§å¸)"].astype(str).str.extract(r"\(([A-Za-z]{3})\)").iloc[:, 0]

    # æ•°å€¼åŒ–ï¼ˆè‹¥åˆ—ç¼ºå¤±åˆ™è¡¥ NaNï¼‰
    for c in ["æ”¶å…¥", "æ”¶å…¥.1", "è°ƒæ•´", "é¢„æ‰£ç¨", "æ€»æ¬ æ¬¾", "æ±‡ç‡"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
        else:
            df[c] = np.nan

    # å¸ç§èšåˆ
    grp = df.dropna(subset=["Currency"]).groupby("Currency", dropna=False).agg(
        local_sum=("æ€»æ¬ æ¬¾","sum"),
        usd_sum=("æ”¶å…¥.1","sum"),
        adj_sum=("è°ƒæ•´","sum"),
        wht_sum=("é¢„æ‰£ç¨","sum"),
    ).reset_index()

    # æ±‡ç‡(USD/æœ¬å¸)ï¼šâˆ‘USD / âˆ‘æœ¬å¸
    grp["rate_usd_per_local"] = np.where(
        grp["local_sum"].abs() > 0,
        grp["usd_sum"].abs() / grp["local_sum"].abs(),
        np.nan
    )

    # (è°ƒæ•´+é¢„æ‰£ç¨) æŠ˜ç¾å…ƒï¼ˆä¹˜æ³•ï¼‰
    grp["AdjTaxUSD"] = (grp["adj_sum"].fillna(0) + grp["wht_sum"].fillna(0)) * grp["rate_usd_per_local"]

    audit = grp.rename(columns={
        "local_sum": "æœ¬å¸æ€»æ¬ æ¬¾",
        "usd_sum": "ç¾å…ƒæ”¶å…¥åˆè®¡(æ”¶å…¥.1)",
        "adj_sum": "è°ƒæ•´(æœ¬å¸)åˆè®¡",
        "wht_sum": "é¢„æ‰£ç¨(æœ¬å¸)åˆè®¡",
        "rate_usd_per_local": "æ±‡ç‡(USD/æœ¬å¸)"
    })
    return audit

def build_rates_and_totals(audit_df: pd.DataFrame):
    rates = dict(zip(audit_df["Currency"], audit_df["æ±‡ç‡(USD/æœ¬å¸)"]))
    report_total_usd = float(pd.to_numeric(audit_df["ç¾å…ƒæ”¶å…¥åˆè®¡(æ”¶å…¥.1)"], errors="coerce").sum())
    total_adj_usd = float(pd.to_numeric(audit_df["AdjTaxUSD"], errors="coerce").sum())
    return rates, total_adj_usd, report_total_usd

# ---------------- äº¤æ˜“è¡¨ï¼šè‡ªåŠ¨è¯†åˆ« + å¼ºåˆ¶äººå·¥ç¡®è®¤ + è‡ªæ£€ ----------------
# ä¸­æ–‡å¸å â†’ 3 ä½ä»£ç ï¼ˆå¯æŒ‰éœ€æ‰©å……ï¼‰
_CNY_MAP = {
    "äººæ°‘å¸": "CNY","ç¾å…ƒ": "USD","æ¬§å…ƒ": "EUR","æ—¥å…ƒ": "JPY","è‹±é•‘": "GBP","æ¸¯å¸": "HKD",
    "æ–°å°å¸": "TWD","å°å¸":"TWD","éŸ©å…ƒ": "KRW","æ¾³å…ƒ": "AUD","åŠ å…ƒ":"CAD","æ–°è¥¿å…°å…ƒ":"NZD",
    "å¢å¸ƒ":"RUB","é‡Œæ‹‰":"TRY","å…°ç‰¹":"ZAR","ç‘éƒ":"CHF","æ–°åŠ å¡å…ƒ":"SGD","æ²™ç‰¹é‡Œäºšå°”":"SAR",
    "é˜¿è”é…‹è¿ªæ‹‰å§†":"AED","æ³°é“¢":"THB","æ–°è°¢å…‹å°”":"ILS","åŒˆç‰™åˆ©ç¦æ—":"HUF","æ·å…‹å…‹æœ—":"CZK",
    "ä¸¹éº¦å…‹æœ—":"DKK","æŒªå¨å…‹æœ—":"NOK","ç‘å…¸å…‹æœ—":"SEK","æ³¢å…°å…¹ç½—æ":"PLN","ç½—é©¬å°¼äºšåˆ—ä¼Š":"RON",
    "å¢¨è¥¿å“¥æ¯”ç´¢":"MXN","å·´è¥¿é›·äºšå°”":"BRL","æ™ºåˆ©æ¯”ç´¢":"CLP","æ–°å°å¹£":"TWD"
}

def _parse_numeric(s: pd.Series) -> pd.Series:
    t = s.astype(str).str.replace(",", "", regex=False).str.replace(r"[^\d\.\-\+]", "", regex=True)
    return pd.to_numeric(t, errors="coerce")

def _auto_guess_tx_cols_by_values(df: pd.DataFrame):
    cols = list(df.columns)
    norm_map = {c: _norm_colkey(c) for c in cols}

    # ===== 1) é‡‘é¢åˆ—ï¼ˆé˜²ä¸²åˆ—ï¼šè‡ªåŠ¨æ’é™¤â€œåƒIDâ€çš„é•¿æ•´å‹åˆ—ï¼‰ =====
    # å…ˆæŒ‰å…³é”®è¯å‘½ä¸­
    amount = None
    for c, n in norm_map.items():
        if ('extended' in n and 'partner' in n and ('share' in n or 'proceeds' in n or 'amount' in n)) \
           or ('partnershareextended' in n) \
           or (('partnershare' in n or 'partnerproceeds' in n) and ('amount' in n or 'gross' in n or 'net' in n)) \
           or (('proceeds' in n or 'revenue' in n or 'amount' in n) and ('partner' in n or 'publisher' in n)):
            amount = c; break

    # å…œåº•ï¼šåˆ†å¸ƒè¯„åˆ† + æ’é™¤â€œç–‘ä¼¼IDâ€
    candidates = []
    for c in cols:
        v = _parse_numeric(df[c])
        if v.notna().mean() < 0.3:
            continue
        # ç–‘ä¼¼IDï¼šå¤§å¤šæ˜¯æ•´æ•° & p99 >= 1e9ï¼ˆ10ä½çº§ï¼‰
        ints_ratio = (v.dropna() == np.floor(v.dropna())).mean() if v.notna().any() else 0
        p99 = v.quantile(0.99) if v.notna().any() else 0
        if ints_ratio > 0.95 and p99 >= 1e9:
            continue  # æ’é™¤IDæ ·å¼åˆ—

        # è¯„åˆ†ï¼šéç©ºæ•°ã€å¤šæ ·æ€§ã€ä¸­ä½é‡çº§ï¼ˆè¿‡å¤§é™æƒï¼‰
        score = (
            v.notna().sum(),
            float(np.nanmedian(np.abs(v))) if v.notna().any() else 0.0,
            -float(np.nanquantile(np.abs(v), 0.99)) if v.notna().any() else 0.0
        )
        candidates.append((score, c))
    if amount is None:
        if candidates:
            candidates.sort(reverse=True)
            amount = candidates[0][1]
        else:
            # ä¸‡ä¸å¾—å·²ï¼šå›é€€åˆ°â€œéç©ºå¤š&æ€»å’Œå¤§â€
            best = None; best_score = (-1, -1)
            for c in cols:
                v = _parse_numeric(df[c])
                score = (v.notna().sum(), v.abs().sum(skipna=True))
                if score > best_score:
                    best, best_score = c, score
            amount = best

    # ===== 2) å¸ç§åˆ— =====
    def ccy_score(series: pd.Series) -> float:
        s = series.dropna().astype(str).str.strip()
        token = s.str.extract(r"([A-Z]{3})")[0]
        rate = token.notna().mean() if len(s) else 0
        bonus = 0.15 if 'currency' in _norm_colkey(series.name) or 'isocode' in _norm_colkey(series.name) else 0.0
        return rate + bonus
    c_scores = {c: ccy_score(df[c]) for c in cols}
    currency = max(c_scores, key=c_scores.get)

    # ===== 3) SKU åˆ— =====
    sku = None
    for c, n in norm_map.items():
        if n == 'sku' or n.endswith('sku') or 'productid' in n or n == 'productid' or n == 'itemid':
            sku = c; break
    if sku is None and 'SKU' in cols:
        sku = 'SKU'
    if sku is None:
        text_scores = {}
        for c in cols:
            s = df[c].astype(str)
            v = _parse_numeric(s)
            nonnum_ratio = v.isna().mean()
            nunique = s.nunique(dropna=True)
            text_scores[c] = (nonnum_ratio, nunique)
        sku = max(text_scores, key=lambda c: (text_scores[c][0], text_scores[c][1]))

    return amount, currency, sku

def read_tx(uploaded, report_rates: dict):
    df = _read_any(uploaded)
    df.columns = [str(c).strip() for c in df.columns]
    st.subheader("ğŸ“Š äº¤æ˜“è¡¨é¢„è§ˆ")
    st.write("åˆ—åï¼š", list(df.columns))
    st.dataframe(df.head())

    a, c, s = _auto_guess_tx_cols_by_values(df)
    cols = list(df.columns)
    with st.expander("ğŸ›  æ‰‹åŠ¨åˆ—æ˜ å°„ï¼ˆè¯·ç¡®è®¤/ä¿®æ­£ï¼‰", expanded=True):
        a = st.selectbox("é‡‘é¢åˆ—ï¼ˆExtended Partner Share / Proceeds / Amountï¼‰", cols, index=(cols.index(a) if a in cols else 0))
        c = st.selectbox("å¸ç§åˆ—ï¼ˆ3ä½ä»£ç æˆ–ä¸­æ–‡å¸åï¼‰", cols, index=(cols.index(c) if c in cols else 0))
        s = st.selectbox("SKU åˆ—ï¼ˆSKU / Product ID / Item IDï¼‰", cols, index=(cols.index(s) if s in cols else 0))
        unit = st.radio("é‡‘é¢å•ä½", ["å•ä½å…ƒï¼ˆä¸ç”¨æ¢ï¼‰", "å•ä½åˆ†ï¼ˆÃ·100ï¼‰", "å•ä½å˜ï¼ˆÃ·1000ï¼‰"], index=0, horizontal=True)

    df = df.rename(columns={a:"Extended Partner Share", c:"Partner Share Currency", s:"SKU"})

    need = {"Extended Partner Share","Partner Share Currency","SKU"}
    missing = need - set(df.columns)
    if missing:
        st.error(f"ç³»ç»ŸçŒœæµ‹ï¼šé‡‘é¢={a} å¸ç§={c} SKU={s}")
        raise ValueError(f"âŒ äº¤æ˜“è¡¨ç¼ºåˆ—ï¼š{missing}")

    # é‡‘é¢æ¸…æ´— + å•ä½æ¢ç®—
    amt = _parse_numeric(df["Extended Partner Share"])
    if unit == "å•ä½åˆ†ï¼ˆÃ·100ï¼‰":
        amt = amt / 100.0
    elif unit == "å•ä½å˜ï¼ˆÃ·1000ï¼‰":
        amt = amt / 1000.0
    df["Extended Partner Share"] = amt

    # å¸ç§æ ‡å‡†åŒ–ï¼ˆä¸­æ–‡å/æ‹¬å·å†…ä»£ç  â†’ 3ä½ä»£ç  â†’ å¤§å†™ï¼‰
    cval = df["Partner Share Currency"].astype(str).str.strip()
    code_from_paren = cval.str.extract(r"\(([A-Za-z]{3})\)", expand=False)
    final_ccy = cval.str.upper()
    final_ccy = np.where(code_from_paren.notna(), code_from_paren.str.upper(), final_ccy)
    final_ccy = pd.Series(final_ccy).replace(_CNY_MAP).str.upper()
    df["Partner Share Currency"] = final_ccy

    # â€”â€” è‡ªæ£€ 1ï¼šé‡‘é¢åˆ†å¸ƒï¼ˆå¤§é¢é˜»æ–­ï¼‰
    desc = amt.describe(percentiles=[0.5,0.9,0.99])
    p99, vmax = float(desc.get("99%", np.nan)), float(desc.get("max", np.nan))
    st.info(f"é‡‘é¢ç»Ÿè®¡ï¼šmin={desc.get('min',np.nan):.2f}, median={desc.get('50%',np.nan):.2f}, "
            f"p90={desc.get('90%',np.nan):.2f}, p99={p99:.2f}, max={vmax:.2f}")
    big_idx = np.argsort(-amt.fillna(0).to_numpy())[:20]
    st.caption("Top 20 å¤§é¢æ ·æœ¬ï¼ˆç”¨äºè‡ªæ£€ï¼‰")
    st.dataframe(df.iloc[big_idx][["Extended Partner Share","Partner Share Currency","SKU"]])
    if p99 > 1e6 or vmax > 1e8:
        st.error("âš ï¸ é‡‘é¢åˆ†å¸ƒå¼‚å¸¸å¤§ï¼šå¯èƒ½é‡‘é¢åˆ—é€‰é”™æˆ–é‡‘é¢å•ä½ä¸æ˜¯â€œå…ƒâ€ã€‚è¯·æ£€æŸ¥æ˜ å°„ä¸â€œé‡‘é¢å•ä½â€ã€‚")
        st.stop()

    # â€”â€” è‡ªæ£€ 2ï¼šå¸ç§é›†åˆå¯¹é½ï¼ˆç¼ºå¤±é˜»æ–­ï¼‰
    tx_ccy = set(df["Partner Share Currency"].dropna().unique().tolist())
    report_ccy = set(k for k,v in report_rates.items() if np.isfinite(v))
    st.write("äº¤æ˜“è¡¨å¸ç§ä¸ªæ•°ï¼š", len(tx_ccy), "ï¼›è´¢æŠ¥å¯ç”¨å¸ç§ä¸ªæ•°ï¼š", len(report_ccy))
    st.write("äº¤é›†æ ·ä¾‹ï¼š", sorted(list(tx_ccy & report_ccy))[:20])
    missing_in_report = sorted(tx_ccy - report_ccy)
    if missing_in_report:
        st.error(f"âš ï¸ ä»¥ä¸‹å¸ç§åœ¨è´¢æŠ¥ä¸­ä¸å­˜åœ¨æˆ–æ— æ³•è®¡ç®—æ±‡ç‡ï¼š{missing_in_report}ã€‚è¯·ä¿®æ­£äº¤æ˜“è¡¨å¸ç§æˆ–è´¢æŠ¥ã€‚")
        st.stop()

    return df

# ---------------- æ˜ å°„è¡¨ ----------------
def read_map(uploaded):
    mp = _read_any(uploaded, header=0)
    mp.columns = [str(c).strip() for c in mp.columns]
    st.subheader("ğŸ“Š æ˜ å°„è¡¨é¢„è§ˆ")
    st.write("åˆ—åï¼š", list(mp.columns))
    st.dataframe(mp.head())
    if not {"é¡¹ç›®","SKU"}.issubset(mp.columns):
        raise ValueError("âŒ æ˜ å°„è¡¨ç¼ºåˆ—ï¼šé¡¹ç›® æˆ– SKU")
    mp = mp.assign(SKU=mp["SKU"].astype(str).str.split("\n")).explode("SKU")
    mp["SKU"] = mp["SKU"].str.strip()
    mp = mp[mp["SKU"] != ""]
    return mp[["é¡¹ç›®","SKU"]]

# ---------------- é¡µé¢ä¸Šä¼  ----------------
c1, c2, c3 = st.columns(3)
with c1: tx = st.file_uploader("â‘  äº¤æ˜“è¡¨ï¼ˆCSV/XLSXï¼‰", type=["csv","xlsx","xls"], key="tx")
with c2: rp = st.file_uploader("â‘¡ Apple è´¢æŠ¥ï¼ˆçŸ©é˜µï¼ŒCSV/XLSXï¼‰", type=["csv","xlsx","xls"], key="rp")
with c3: mp = st.file_uploader("â‘¢ é¡¹ç›®-SKUï¼ˆXLSXï¼‰", type=["xlsx","xls"], key="mp")

strict_check = st.checkbox("ä¸¥æ ¼æ ¡éªŒï¼šå‡€é¢æ€»å’Œâ‰ˆè´¢æŠ¥ç¾å…ƒæ”¶å…¥ï¼ˆå®¹å·® $0.5 USDï¼‰", value=True)

if st.button("ğŸš€ å¼€å§‹è®¡ç®—ï¼ˆUSD/æœ¬å¸ | å¼ºæ ¡éªŒï¼‰"):
    if not (tx and rp and mp):
        st.error("âŒ è¯·å…ˆä¸Šä¼ ä¸‰ä»½æ–‡ä»¶")
    else:
        try:
            # 1) è´¢æŠ¥ â†’ å®¡è®¡è¡¨ï¼ˆUSD/æœ¬å¸ï¼‰
            audit = read_report_matrix(rp)
            rates, total_adj_usd, report_total_usd = build_rates_and_totals(audit)

            # 2) äº¤æ˜“ + è‡ªæ£€
            txdf = read_tx(tx, rates)
            mpdf = read_map(mp)
            sku2proj = dict(zip(mpdf["SKU"], mpdf["é¡¹ç›®"]))

            # 3) äº¤æ˜“æ¢ç®—ç¾å…ƒï¼ˆä¹˜ä»¥ USD/æœ¬å¸ï¼‰
            txdf["rate_usd_per_local"] = txdf["Partner Share Currency"].map(rates)
            txdf["Extended Partner Share USD"] = txdf["Extended Partner Share"] * txdf["rate_usd_per_local"]

            tx_total_usd = float(pd.to_numeric(txdf["Extended Partner Share USD"], errors="coerce").sum())
            if not np.isfinite(tx_total_usd) or tx_total_usd == 0:
                st.error("âŒ äº¤æ˜“ USD åˆè®¡ä¸º 0ï¼šæ£€æŸ¥é‡‘é¢åˆ—/é‡‘é¢å•ä½/å¸ç§æ˜ å°„")
                st.stop()

            # 4) æˆæœ¬åˆ†æ‘Šï¼ˆæŒ‰äº¤æ˜“ USD å æ¯”ï¼‰
            txdf["Cost Allocation (USD)"] = txdf["Extended Partner Share USD"] / tx_total_usd * total_adj_usd
            txdf["Net Partner Share (USD)"] = txdf["Extended Partner Share USD"] + txdf["Cost Allocation (USD)"]
            txdf["é¡¹ç›®"] = txdf["SKU"].astype(str).map(sku2proj)

            # 5) é¡¹ç›®æ±‡æ€»
            summary = txdf.groupby("é¡¹ç›®", dropna=False)[
                ["Extended Partner Share USD", "Cost Allocation (USD)", "Net Partner Share (USD)"]
            ].sum().reset_index()

            # 6) æ ¡éªŒï¼šå‡€é¢ â‰ˆ è´¢æŠ¥ç¾å…ƒæ”¶å…¥
            net_total = float(pd.to_numeric(txdf["Net Partner Share (USD)"], errors="coerce").sum())
            diff = net_total - report_total_usd
            if strict_check and (not np.isfinite(diff) or abs(diff) > 0.5):
                st.error(f"âŒ å¯¹è´¦å¤±è´¥ï¼šäº¤æ˜“å‡€é¢ {net_total:,.2f} USD ä¸è´¢æŠ¥ {report_total_usd:,.2f} USD å·®å¼‚ {diff:,.2f}ã€‚"
                         "è¯·æ£€æŸ¥é‡‘é¢åˆ—/é‡‘é¢å•ä½/å¸ç§ã€‚")
                st.stop()

            # 7) æ€»è¡Œä¸ä¸‹è½½
            total_row = {
                "é¡¹ç›®": "__TOTAL__",
                "Extended Partner Share USD": float(summary["Extended Partner Share USD"].sum()),
                "Cost Allocation (USD)": float(summary["Cost Allocation (USD)"].sum()),
                "Net Partner Share (USD)": float(summary["Net Partner Share (USD)"].sum()),
            }
            summary = pd.concat([summary, pd.DataFrame([total_row])], ignore_index=True)

            st.success("âœ… è®¡ç®—å®Œæˆ")
            st.markdown(f"- è´¢æŠ¥ç¾å…ƒæ”¶å…¥åˆè®¡ï¼ˆâˆ‘æ”¶å…¥.1ï¼‰ï¼š**{report_total_usd:,.2f} USD**")
            st.markdown(f"- åˆ†æ‘Šæ€»é¢ï¼ˆè°ƒæ•´+é¢„æ‰£ç¨ â†’ USDï¼‰ï¼š**{total_adj_usd:,.2f} USD**")
            st.markdown(f"- äº¤æ˜“æ¯›æ”¶å…¥ USD åˆè®¡ï¼š**{tx_total_usd:,.2f} USD**")
            st.markdown(f"- äº¤æ˜“å‡€é¢ USD åˆè®¡ï¼š**{net_total:,.2f} USD**ï¼Œå·®å¼‚ï¼š**{diff:,.2f} USD**")

            st.download_button("â¬‡ï¸ å®¡è®¡ï¼šæ¯å¸ç§æ±‡ç‡ä¸åˆ†æ‘Š (CSV)",
                               data=audit.to_csv(index=False).encode("utf-8-sig"),
                               file_name="financial_report_currency_rates.csv", mime="text/csv")
            st.download_button("â¬‡ï¸ é€å•ç»“æœ (CSV)",
                               data=txdf.to_csv(index=False).encode("utf-8-sig"),
                               file_name="transactions_usd_net_project.csv", mime="text/csv")
            st.download_button("â¬‡ï¸ é¡¹ç›®æ±‡æ€» (CSV)",
                               data=summary.to_csv(index=False).encode("utf-8-sig"),
                               file_name="project_summary.csv", mime="text/csv")

            with st.expander("é¢„è§ˆï¼šè´¢æŠ¥å®¡è®¡ï¼ˆUSD/æœ¬å¸ï¼‰", expanded=False):
                st.dataframe(audit)
            with st.expander("é¢„è§ˆï¼šé€å•ç»“æœ", expanded=False):
                st.dataframe(txdf.head(200))
            with st.expander("é¢„è§ˆï¼šé¡¹ç›®æ±‡æ€»", expanded=True):
                st.dataframe(summary)

        except Exception as e:
            st.error(f"âš ï¸ å‡ºé”™ï¼š{e}")
            st.exception(e)
