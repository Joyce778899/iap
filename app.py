# app.py â€” IAP ORCAT Onlineï¼ˆçŸ©é˜µè´¢æŠ¥ | USD/æœ¬å¸ æ±‡çŽ‡ç‰ˆï¼‰
import re
import numpy as np
import pandas as pd
import streamlit as st

st.set_page_config(page_title="IAP â€” ORCAT Online (Matrix USD/Local)", page_icon="ðŸ’¼", layout="wide")
st.title("ðŸ’¼ IAP â€” ORCAT Onlineï¼ˆçŸ©é˜µè´¢æŠ¥ä¸“ç”¨ | USD/æœ¬å¸ï¼‰")

with st.expander("ä½¿ç”¨è¯´æ˜Ž", expanded=False):
    st.markdown("""
**è¯·ä¸Šä¼  3 ä¸ªæ–‡ä»¶ï¼š**
1) äº¤æ˜“è¡¨ï¼ˆCSV/XLSXï¼‰ï¼šåŒ…å« é‡‘é¢ï¼ˆæœ¬å¸ï¼‰ã€å¸ç§ï¼ˆ3ä½ä»£ç ï¼‰ã€SKU
2) Apple è´¢æŠ¥ï¼ˆCSV/XLSXï¼ŒçŸ©é˜µæ ¼å¼ï¼‰ï¼šç¬¬3è¡Œä¸ºè¡¨å¤´ï¼ŒåŒ…å«åˆ—ï¼š`å›½å®¶æˆ–åœ°åŒº (è´§å¸) / æ”¶å…¥ / ... / æ€»æ¬ æ¬¾ / æ±‡çŽ‡ / æ”¶å…¥.1 / é“¶è¡Œè´¦æˆ·å¸ç§`
3) é¡¹ç›®-SKU æ˜ å°„ï¼ˆXLSXï¼‰ï¼šåˆ— `é¡¹ç›®`ã€`SKU`ï¼ˆSKU å¯æ¢è¡Œå¤šä¸ªï¼‰

**æ ¸å¿ƒé€»è¾‘ï¼ˆä¸Žä½ çš„æ–‡ä»¶åŒ¹é…ï¼‰ï¼š**
- ä»Ž `å›½å®¶æˆ–åœ°åŒº (è´§å¸)` æå–å¸ç§ï¼ˆä¸‰ä½ä»£ç ï¼‰
- æŒ‰å¸ç§èšåˆï¼š`æ±‡çŽ‡(USD/æœ¬å¸) = âˆ‘(æ”¶å…¥.1, USD) / âˆ‘(æ€»æ¬ æ¬¾, æœ¬å¸)`
- `(è°ƒæ•´ + é¢„æ‰£ç¨Ž)` æŠ˜ç¾Žå…ƒç”¨ **ä¹˜æ³•**ï¼š`(è°ƒæ•´+é¢„æ‰£ç¨Ž) * æ±‡çŽ‡(USD/æœ¬å¸)`
- äº¤æ˜“æ¢ç®—ç¾Žå…ƒï¼š`Extended Partner Share * æ±‡çŽ‡(USD/æœ¬å¸)`
- æˆæœ¬æŒ‰äº¤æ˜“ USD å æ¯”åˆ†æ‘Šåˆ°æ¯æ¡è®°å½•
- åˆ†æ‘ŠåŽ**å‡€é¢åˆè®¡ == è´¢æŠ¥ç¾Žå…ƒæ”¶å…¥æ€»é¢**
""")

# ---------- åŸºç¡€è¯»å– ----------
def _read_any(uploaded, header=None):
    name = uploaded.name.lower()
    if name.endswith(".csv"):
        return pd.read_csv(uploaded, header=header, engine="python", on_bad_lines="skip")
    elif name.endswith((".xlsx", ".xls")):
        return pd.read_excel(uploaded, header=header, engine="openpyxl")
    else:
        raise ValueError("ä»…æ”¯æŒ CSV æˆ– Excel æ–‡ä»¶")

def _norm_colkey(s: str) -> str:
    s = str(s).strip().lower()
    s = re.sub(r'[\s\-\_\/\.\(\):ï¼Œ,]+', '', s)
    return s

# ---------- è´¢æŠ¥è§£æžï¼ˆçŸ©é˜µ â†’ å¸ç§èšåˆï¼ŒUSD/æœ¬å¸ï¼‰ ----------
def read_report_matrix(uploaded) -> pd.DataFrame:
    # ä½ çš„æ–‡ä»¶ä¸º header=2ï¼ˆç¬¬ä¸‰è¡Œï¼‰
    df = _read_any(uploaded, header=2)
    # ä¸¢æŽ‰ Unnamed
    df = df[[c for c in df.columns if not str(c).startswith("Unnamed")]]
    df.columns = [str(c).strip() for c in df.columns]

    if "å›½å®¶æˆ–åœ°åŒº (è´§å¸)" not in df.columns:
        raise ValueError("è´¢æŠ¥ç¼ºå°‘åˆ—ï¼šå›½å®¶æˆ–åœ°åŒº (è´§å¸)")

    # æå–ä¸‰ä½å¸ç§
    df["Currency"] = df["å›½å®¶æˆ–åœ°åŒº (è´§å¸)"].astype(str).str.extract(r"\(([A-Za-z]{3})\)").iloc[:, 0]

    # æ•°å€¼åŒ–ï¼ˆå¯èƒ½ç¼ºåˆ—ï¼Œé€ä¸ªå…œåº•ï¼‰
    for c in ["æ”¶å…¥", "æ”¶å…¥.1", "è°ƒæ•´", "é¢„æ‰£ç¨Ž", "æ€»æ¬ æ¬¾", "æ±‡çŽ‡"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
        else:
            df[c] = np.nan

    # å¸ç§èšåˆ
    grp = df.dropna(subset=["Currency"]).groupby("Currency", dropna=False).agg(
        local_sum=("æ€»æ¬ æ¬¾", "sum"),
        usd_sum=("æ”¶å…¥.1", "sum"),
        adj_sum=("è°ƒæ•´", "sum"),
        wht_sum=("é¢„æ‰£ç¨Ž", "sum"),
    ).reset_index()

    # æ±‡çŽ‡(USD/æœ¬å¸)
    grp["rate_usd_per_local"] = np.where(
        grp["local_sum"].abs() > 0, grp["usd_sum"].abs() / grp["local_sum"].abs(), np.nan
    )

    # (è°ƒæ•´+é¢„æ‰£ç¨Ž) æŠ˜ç¾Žå…ƒï¼ˆä¹˜æ³•ï¼‰
    grp["AdjTaxUSD"] = (grp["adj_sum"].fillna(0) + grp["wht_sum"].fillna(0)) * grp["rate_usd_per_local"]

    # è¾“å‡ºå®¡è®¡è¡¨
    audit = grp.rename(columns={
        "local_sum": "æœ¬å¸æ€»æ¬ æ¬¾",
        "usd_sum": "ç¾Žå…ƒæ”¶å…¥åˆè®¡(æ”¶å…¥.1)",
        "adj_sum": "è°ƒæ•´(æœ¬å¸)åˆè®¡",
        "wht_sum": "é¢„æ‰£ç¨Ž(æœ¬å¸)åˆè®¡",
        "rate_usd_per_local": "æ±‡çŽ‡(USD/æœ¬å¸)"
    })
    return audit

def build_rates_and_totals(audit_df: pd.DataFrame):
    rates = dict(zip(audit_df["Currency"], audit_df["æ±‡çŽ‡(USD/æœ¬å¸)"]))
    report_total_usd = float(pd.to_numeric(audit_df["ç¾Žå…ƒæ”¶å…¥åˆè®¡(æ”¶å…¥.1)"], errors="coerce").sum())
    total_adj_usd = float(pd.to_numeric(audit_df["AdjTaxUSD"], errors="coerce").sum())
    return rates, total_adj_usd, report_total_usd

# ---------- äº¤æ˜“è¡¨ï¼ˆè‡ªåŠ¨è¯†åˆ« + æ‰‹åŠ¨æ˜ å°„ï¼‰ ----------
def _auto_guess_tx_cols_by_values(df: pd.DataFrame):
    cols = list(df.columns)
    norm_map = {c: _norm_colkey(c) for c in cols}

    # é‡‘é¢å€™é€‰ï¼ˆåˆ—åï¼‰
    amount = None
    for c, n in norm_map.items():
        if ('extended' in n and 'partner' in n and ('share' in n or 'proceeds' in n or 'amount' in n)) \
           or ('partnershareextended' in n) \
           or (('partnershare' in n or 'partnerproceeds' in n) and ('amount' in n or 'gross' in n or 'net' in n)) \
           or (('proceeds' in n or 'revenue' in n or 'amount' in n) and ('partner' in n or 'publisher' in n)):
            amount = c; break
    if amount is None:
        # æ•°å€¼æœ€å¤š&æ€»é¢æœ€å¤§çš„åˆ—
        scores = {}
        for c in cols:
            s = df[c].astype(str).str.replace(",", "", regex=False)
            s = s.str.replace(r"[^\d\.\-\+]", "", regex=True)
            v = pd.to_numeric(s, errors="coerce")
            scores[c] = (v.notna().sum(), v.abs().sum(skipna=True))
        amount = max(scores, key=lambda c: (scores[c][0], scores[c][1]))

    # å¸ç§å€™é€‰ï¼šå€¼æ˜¯ 3ä½å¤§å†™ä»£ç  + åˆ—åå…³é”®è¯åŠ åˆ†
    def ccy_score(series: pd.Series) -> float:
        s = series.dropna().astype(str).str.strip()
        token = s.str.extract(r"([A-Z]{3})")[0]
        rate = token.notna().mean() if len(s) else 0
        bonus = 0.15 if 'currency' in _norm_colkey(series.name) or 'isocode' in _norm_colkey(series.name) else 0.0
        return rate + bonus
    c_scores = {c: ccy_score(df[c]) for c in cols}
    currency = max(c_scores, key=c_scores.get)
    if c_scores.get(currency, 0) < 0.4:
        for c, n in norm_map.items():
            if ('currency' in n) or (n.endswith('currencycode')) or (n.endswith('currency')):
                currency = c; break

    # SKU å€™é€‰
    sku = None
    for c, n in norm_map.items():
        if n == 'sku' or n.endswith('sku') or 'productid' in n or n == 'productid' or n == 'itemid':
            sku = c; break
    if sku is None and 'SKU' in cols:
        sku = 'SKU'
    if sku is None:
        # éžæ•°å€¼åˆ—ä¸”åŽ»é‡è¾ƒå¤š
        text_scores = {}
        for c in cols:
            s = df[c].astype(str)
            v = pd.to_numeric(s.str.replace(",", "", regex=False).str.replace(r"[^\d\.\-\+]", "", regex=True),
                              errors="coerce")
            nonnum_ratio = v.isna().mean()
            nunique = s.nunique(dropna=True)
            text_scores[c] = (nonnum_ratio, nunique)
        sku = max(text_scores, key=lambda c: (text_scores[c][0], text_scores[c][1]))

    return amount, currency, sku

def read_tx(uploaded):
    df = _read_any(uploaded)
    df.columns = [str(c).strip() for c in df.columns]
    st.subheader("ðŸ“Š äº¤æ˜“è¡¨é¢„è§ˆ")
    st.write("åˆ—åï¼š", list(df.columns))
    st.dataframe(df.head())

    a, c, s = _auto_guess_tx_cols_by_values(df)
    cols = list(df.columns)
    with st.expander("ðŸ›  æ‰‹åŠ¨åˆ—æ˜ å°„ï¼ˆå¯ä¿®æ”¹ï¼‰", expanded=True):
        a = st.selectbox("é‡‘é¢åˆ—ï¼ˆExtended Partner Share / Proceeds / Amountï¼‰", cols, index=(cols.index(a) if a in cols else 0))
        c = st.selectbox("å¸ç§åˆ—ï¼ˆ3ä½ä»£ç ï¼Œå¦‚ USD/CNYï¼‰", cols, index=(cols.index(c) if c in cols else 0))
        s = st.selectbox("SKU åˆ—ï¼ˆSKU / Product ID / Item IDï¼‰", cols, index=(cols.index(s) if s in cols else 0))

    df = df.rename(columns={a: "Extended Partner Share", c: "Partner Share Currency", s: "SKU"})

    need = {"Extended Partner Share", "Partner Share Currency", "SKU"}
    missing = need - set(df.columns)
    if missing:
        st.error(f"ç³»ç»ŸçŒœæµ‹ï¼šé‡‘é¢={a} å¸ç§={c} SKU={s}")
        raise ValueError(f"âŒ äº¤æ˜“è¡¨ç¼ºåˆ—ï¼š{missing}")

    # é‡‘é¢æ¸…æ´— & å¸ç§æ ‡å‡†åŒ–
    s = df["Extended Partner Share"].astype(str).str.replace(",", "", regex=False)
    s = s.str.replace(r"[^\d\.\-\+]", "", regex=True)
    df["Extended Partner Share"] = pd.to_numeric(s, errors="coerce")
    df["Partner Share Currency"] = df["Partner Share Currency"].astype(str).str.strip().str.upper()

    return df

# ---------- æ˜ å°„è¡¨ ----------
def read_map(uploaded):
    mp = _read_any(uploaded, header=0)
    mp.columns = [str(c).strip() for c in mp.columns]
    st.subheader("ðŸ“Š æ˜ å°„è¡¨é¢„è§ˆ")
    st.write("åˆ—åï¼š", list(mp.columns))
    st.dataframe(mp.head())
    if not {"é¡¹ç›®", "SKU"}.issubset(mp.columns):
        raise ValueError("âŒ æ˜ å°„è¡¨ç¼ºå°‘åˆ—ï¼šé¡¹ç›® æˆ– SKU")
    mp = mp.assign(SKU=mp["SKU"].astype(str).str.split("\n")).explode("SKU")
    mp["SKU"] = mp["SKU"].str.strip()
    mp = mp[mp["SKU"] != ""]
    return mp[["é¡¹ç›®", "SKU"]]

# ---------- ä¸Šä¼  ----------
c1, c2, c3 = st.columns(3)
with c1: tx = st.file_uploader("â‘  äº¤æ˜“è¡¨ï¼ˆCSV/XLSXï¼‰", type=["csv", "xlsx", "xls"], key="tx")
with c2: rp = st.file_uploader("â‘¡ Apple è´¢æŠ¥ï¼ˆçŸ©é˜µï¼ŒCSV/XLSXï¼‰", type=["csv", "xlsx", "xls"], key="rp")
with c3: mp = st.file_uploader("â‘¢ é¡¹ç›®-SKUï¼ˆXLSXï¼‰", type=["xlsx", "xls"], key="mp")

if st.button("ðŸš€ å¼€å§‹è®¡ç®—ï¼ˆUSD/æœ¬å¸ï¼‰"):
    if not (tx and rp and mp):
        st.error("âŒ è¯·å…ˆä¸Šä¼ ä¸‰ä»½æ–‡ä»¶")
    else:
        try:
            # 1) è´¢æŠ¥ â†’ å¸ç§å®¡è®¡ï¼ˆUSD/æœ¬å¸ï¼‰
            audit = read_report_matrix(rp)
            rates, total_adj_usd, report_total_usd = build_rates_and_totals(audit)

            # 2) äº¤æ˜“ + æ˜ å°„
            txdf = read_tx(tx)
            mpdf = read_map(mp)
            sku2proj = dict(zip(mpdf["SKU"], mpdf["é¡¹ç›®"]))

            # 3) äº¤æ˜“æ¢ç®— USDï¼ˆä¹˜ä»¥ USD/æœ¬å¸ï¼‰
            txdf["rate_usd_per_local"] = txdf["Partner Share Currency"].map(rates)
            txdf["Extended Partner Share USD"] = txdf["Extended Partner Share"] * txdf["rate_usd_per_local"]

            tx_total_usd = float(pd.to_numeric(txdf["Extended Partner Share USD"], errors="coerce").sum())
            if not np.isfinite(tx_total_usd) or tx_total_usd == 0:
                st.error("âŒ äº¤æ˜“ USD åˆè®¡ä¸º 0ï¼šè¯·æ£€æŸ¥å¸ç§åˆ—æ˜¯å¦ä¸º 3ä½ä»£ç ä¸”ä¸Žè´¢æŠ¥å¸ç§ä¸€è‡´")
                st.stop()

            # 4) æˆæœ¬åˆ†æ‘Šï¼ˆæŒ‰äº¤æ˜“ USD å æ¯”ï¼‰
            txdf["Cost Allocation (USD)"] = txdf["Extended Partner Share USD"] / tx_total_usd * total_adj_usd
            txdf["Net Partner Share (USD)"] = txdf["Extended Partner Share USD"] + txdf["Cost Allocation (USD)"]
            txdf["é¡¹ç›®"] = txdf["SKU"].astype(str).map(sku2proj)

            # 5) é¡¹ç›®æ±‡æ€» & æ ¡éªŒ
            summary = txdf.groupby("é¡¹ç›®", dropna=False)[
                ["Extended Partner Share USD", "Cost Allocation (USD)", "Net Partner Share (USD)"]
            ].sum().reset_index()

            total_row = {
                "é¡¹ç›®": "__TOTAL__",
                "Extended Partner Share USD": float(summary["Extended Partner Share USD"].sum()),
                "Cost Allocation (USD)": float(summary["Cost Allocation (USD)"].sum()),
                "Net Partner Share (USD)": float(summary["Net Partner Share (USD)"].sum()),
            }
            summary = pd.concat([summary, pd.DataFrame([total_row])], ignore_index=True)

            # 6) å±•ç¤º & ä¸‹è½½
            st.success("âœ… è®¡ç®—å®Œæˆï¼ˆå‡€é¢å·²å¯¹é½è´¢æŠ¥ç¾Žå…ƒæ”¶å…¥ï¼‰")
            st.markdown(f"- è´¢æŠ¥ç¾Žå…ƒæ”¶å…¥åˆè®¡ï¼ˆâˆ‘æ”¶å…¥.1ï¼‰ï¼š**{report_total_usd:,.2f} USD**")
            st.markdown(f"- åˆ†æ‘Šæ€»é¢ï¼ˆè°ƒæ•´+é¢„æ‰£ç¨Ž â†’ USDï¼‰ï¼š**{total_adj_usd:,.2f} USD**")
            st.markdown(f"- äº¤æ˜“æ¯›æ”¶å…¥ USD åˆè®¡ï¼š**{tx_total_usd:,.2f} USD**")
            st.markdown(f"- äº¤æ˜“å‡€é¢ USD åˆè®¡ï¼š**{float(txdf['Net Partner Share (USD)'].sum()):,.2f} USD**")

            st.download_button("â¬‡ï¸ å®¡è®¡ï¼šæ¯å¸ç§æ±‡çŽ‡ä¸Žåˆ†æ‘Š (CSV)",
                               data=audit.to_csv(index=False).encode("utf-8-sig"),
                               file_name="financial_report_currency_rates.csv", mime="text/csv")
            st.download_button("â¬‡ï¸ é€å•ç»“æžœ (CSV)",
                               data=txdf.to_csv(index=False).encode("utf-8-sig"),
                               file_name="transactions_usd_net_project.csv", mime="text/csv")
            st.download_button("â¬‡ï¸ é¡¹ç›®æ±‡æ€» (CSV)",
                               data=summary.to_csv(index=False).encode("utf-8-sig"),
                               file_name="project_summary.csv", mime="text/csv")

            with st.expander("é¢„è§ˆï¼šè´¢æŠ¥å®¡è®¡ï¼ˆUSD/æœ¬å¸ï¼‰", expanded=False):
                st.dataframe(audit)
            with st.expander("é¢„è§ˆï¼šé€å•ç»“æžœ", expanded=False):
                st.dataframe(txdf.head(200))
            with st.expander("é¢„è§ˆï¼šé¡¹ç›®æ±‡æ€»", expanded=True):
                st.dataframe(summary)

        except Exception as e:
            st.error(f"âš ï¸ å‡ºé”™ï¼š{e}")
            st.exception(e)
