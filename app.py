# app.py
import re
import pandas as pd
import streamlit as st

st.set_page_config(page_title="IAP â€” ORCAT Online (Debug+AutoHeader)", page_icon="ğŸ", layout="wide")
st.title("ğŸ IAP â€” ORCAT Online Debug + AutoHeader")

with st.expander("è¾“å…¥è¦æ±‚ï¼ˆå¿…è¯»ï¼‰", expanded=False):
    st.markdown("""
**äº¤æ˜“æ˜ç»†ï¼ˆCSV/XLSXï¼‰**ï¼šè‡³å°‘åŒ…å«èƒ½è¡¨ç¤º
- é‡‘é¢ï¼ˆæœ¬å¸ï¼‰ï¼šå¦‚ *Extended Partner Share / Proceeds / Amount*
- å¸ç§ï¼šå¦‚ *Partner Share Currency / Currency*
- SKUï¼šå¦‚ *SKU / Product ID / Item ID*

**Apple è´¢æŠ¥ï¼ˆCSV/XLSXï¼‰**ï¼ˆæ”¯æŒæœ€æ–°å¯¼å‡ºæ ¼å¼ï¼‰ï¼š
- è¡¨å¤´åœ¨ç¬¬ 3 è¡Œï¼ˆheader=2ï¼‰ï¼Œæˆ–å‰å‡ è¡Œï¼›è„šæœ¬ä¼šè‡ªåŠ¨è¯†åˆ«
- ä¸¤ä¸ªâ€œæ”¶å…¥â€åˆ—ä¸­ï¼Œ**æœ€åä¸€ä¸ª `æ”¶å…¥.1` ä¸ºç¾å…ƒæ”¶å…¥**ï¼ˆè‹¥ä¸å­˜åœ¨åˆ™ä»åŒ…å«â€œæ”¶å…¥/usd/revenue/proceedsâ€çš„åˆ—å…œåº•ï¼‰
- å…³é”®åˆ—ï¼š`å›½å®¶æˆ–åœ°åŒº (è´§å¸)`ã€`æ€»æ¬ æ¬¾`ã€`æ”¶å…¥.1`ï¼ˆç¾å…ƒï¼‰ã€`è°ƒæ•´`ã€`é¢„æ‰£ç¨`

**é¡¹ç›®-SKUï¼ˆXLSXï¼‰**ï¼š
- åˆ—ï¼š`é¡¹ç›®`ã€`SKU`ï¼ˆSKU å¯æ¢è¡Œåˆ†éš”å¤šä¸ªï¼‰
""")

# ---------- é€šç”¨è¯»å– ----------
def read_any(file, header=None):
    name = file.name.lower()
    if name.endswith(".csv"):
        # å¯¹ CSV ä½¿ç”¨ python å¼•æ“ï¼Œæ”¯æŒ on_bad_lines
        return pd.read_csv(file, header=header, engine="python", on_bad_lines="skip")
    elif name.endswith((".xlsx", ".xls")):
        return pd.read_excel(file, header=header, engine="openpyxl")
    else:
        raise ValueError("ä»…æ”¯æŒ CSV æˆ– Excel (xlsx/xls) æ–‡ä»¶")

# ---------- è´¢æŠ¥è¯»å–ï¼ˆè‡ªåŠ¨è¯†åˆ«è¡¨å¤´ + åˆ—åå˜ä½“ï¼Œé€‚é…ä½ çš„â€œæœ€æ–°æ–‡ä»¶â€ï¼‰ ----------
def read_report(file):
    """
    è‡ªåŠ¨å°è¯• header=2ï¼ˆç¬¬ä¸‰è¡Œè¡¨å¤´ï¼Œé€‚é…ä½ çš„æœ€æ–°æ–‡ä»¶ï¼‰ï¼Œè‹¥å¤±è´¥å†å›é€€ 0..10ï¼›
    å¤„ç†åè¡Œï¼›è¯†åˆ«â€œæ”¶å…¥.1â€ä¸ºç¾å…ƒæ”¶å…¥ï¼ˆè‹¥ä¸å­˜åœ¨åˆ™ä»åŒ…å«â€˜æ”¶å…¥/usd/revenue/proceedsâ€™çš„åˆ—å…œåº•ï¼‰ã€‚
    è¿”å›æ ‡å‡†åˆ—ï¼šCurrency, æ€»æ¬ æ¬¾, æ”¶å…¥.1, è°ƒæ•´, é¢„æ‰£ç¨
    """
    df = None
    tried_headers = []

    # å…ˆæŒ‰ä½ æœ€æ–°æ–‡ä»¶çš„ä¹ æƒ¯ï¼šheader=2
    try:
        file.seek(0)
        df = read_any(file, header=2)
    except Exception:
        df = None

    # è‹¥å¤±è´¥/ä¸å«å…³é”®åˆ—ï¼Œå†å°è¯• 0..10
    def has_currency_col(_df):
        cols = [str(c).strip() for c in _df.columns]
        return any(("è´§å¸" in c) or ("å›½å®¶æˆ–åœ°åŒº" in c) for c in cols)

    if df is None or not has_currency_col(df):
        for h in range(0, 11):
            try:
                file.seek(0)
                temp = read_any(file, header=h)
                tried_headers.append(h)
                if has_currency_col(temp):
                    df = temp
                    break
            except Exception:
                continue

    if df is None:
        raise ValueError(f"âŒ æ— æ³•è¯†åˆ«è´¢æŠ¥è¡¨å¤´ï¼ˆå·²å°è¯• header={ [2]+tried_headers }ï¼‰")

    # æ¸…æ´—åˆ—åä¸æ— ååˆ—
    df.columns = [str(c).strip() for c in df.columns]
    df = df[[c for c in df.columns if not str(c).startswith("Unnamed")]]

    # æ‰¾â€œå›½å®¶æˆ–åœ°åŒº (è´§å¸)â€æˆ–åŒ…å«è´§å¸ä¿¡æ¯çš„åˆ—
    currency_source_col = None
    for c in df.columns:
        if ("å›½å®¶æˆ–åœ°åŒº" in c and "è´§å¸" in c):
            currency_source_col = c; break
    if currency_source_col is None:
        for c in df.columns:
            if "è´§å¸" in c or "currency" in c.lower():
                currency_source_col = c; break
    if currency_source_col is None:
        # é€€ä¸€æ­¥ï¼šä»…â€œå›½å®¶æˆ–åœ°åŒºâ€åˆ—
        for c in df.columns:
            if "å›½å®¶æˆ–åœ°åŒº" in c:
                currency_source_col = c; break
    if currency_source_col is None:
        raise ValueError("âŒ è´¢æŠ¥æœªæ‰¾åˆ°åŒ…å«â€˜è´§å¸â€™æˆ–â€˜å›½å®¶æˆ–åœ°åŒºâ€™çš„åˆ—")

    # ç¾å…ƒæ”¶å…¥åˆ—ï¼šä¼˜å…ˆä½¿ç”¨â€œæ”¶å…¥.1â€ï¼Œå¦åˆ™ä»å³å¾€å·¦æ‰¾åŒ…å«â€œæ”¶å…¥/usd/revenue/proceedsâ€çš„åˆ—
    revenue_col = None
    if "æ”¶å…¥.1" in df.columns:
        revenue_col = "æ”¶å…¥.1"
    else:
        candidates = []
        for c in df.columns:
            cl = c.lower()
            if ("æ”¶å…¥" in c) or ("usd" in cl) or ("revenue" in cl) or ("proceeds" in cl):
                candidates.append(c)
        if candidates:
            revenue_col = candidates[-1]  # å–æœ€å³ä¾§ä¸€ä¸ª
    if revenue_col is None:
        raise ValueError("âŒ è´¢æŠ¥æœªæ‰¾åˆ°ç¾å…ƒæ”¶å…¥åˆ—ï¼ˆæ”¶å…¥.1/åŒ…å«æ”¶å…¥æˆ–usd/revenue/proceeds çš„åˆ—ï¼‰")

    # æœ¬å¸æ€»é¢åˆ—ï¼ˆç”¨äºæ±‡ç‡ï¼‰ï¼šâ€œæ€»æ¬ æ¬¾/æ¬ æ¬¾/æœ¬å¸é‡‘é¢/æœ¬åœ°è´§å¸/local total/amount localâ€
    owed_col = None
    for c in df.columns:
        cl = c.lower()
        if ("æ€»æ¬ æ¬¾" in c) or ("æ¬ æ¬¾" in c) or ("æœ¬å¸é‡‘é¢" in c) or ("æœ¬åœ°è´§å¸" in c) or ("local" in cl and ("total" in cl or "amount" in cl)):
            owed_col = c; break
    if owed_col is None:
        # æœ‰äº›æŠ¥è¡¨â€œæ€»æ¬ æ¬¾â€å°±å«â€œæ€»é¢/é‡‘é¢â€ï¼Œæ­¤å¤„å†å®½ä¸€ç‚¹ï¼ˆä½†å°½é‡é¿å…é€‰åˆ°ç¾å…ƒæ”¶å…¥åˆ—ï¼‰
        for c in df.columns:
            if ("æ€»é¢" in c or "é‡‘é¢" in c) and c != revenue_col:
                owed_col = c; break
    if owed_col is None:
        raise ValueError("âŒ è´¢æŠ¥æœªæ‰¾åˆ°æœ¬å¸æ€»é¢åˆ—ï¼ˆå¦‚â€˜æ€»æ¬ æ¬¾/æœ¬å¸é‡‘é¢/Local Totalâ€™ï¼‰")

    # è°ƒæ•´/é¢„æ‰£ç¨åˆ—ï¼ˆæ— åˆ™ç½® 0ï¼‰
    adj_col = None
    tax_col = None
    for c in df.columns:
        cl = c.lower()
        if ("è°ƒæ•´" in c) or ("adjust" in cl):
            adj_col = c; break
    for c in df.columns:
        cl = c.lower()
        if ("é¢„æ‰£ç¨" in c) or ("withholding" in cl) or ("wht" in cl):
            tax_col = c; break
    if adj_col is None:
        df["__adj__"] = 0; adj_col = "__adj__"
    if tax_col is None:
        df["__tax__"] = 0; tax_col = "__tax__"

    # æ•°å€¼åŒ–
    for c in [owed_col, revenue_col, adj_col, tax_col]:
        df[c] = pd.to_numeric(df[c], errors="coerce")

    # æå–ä¸‰ä½å¸ç§ï¼ˆ(XXX) æˆ– ç›´æ¥ä¸‰å­—æ¯ï¼‰
    def extract_ccy(val):
        s = str(val)
        m = re.search(r"\(([A-Za-z]{3})\)", s)
        if m: return m.group(1).upper()
        m = re.search(r"\b([A-Za-z]{3})\b", s)
        if m: return m.group(1).upper()
        return None

    cur_vals = df[currency_source_col].apply(extract_ccy)
    df = df.assign(
        Currency = cur_vals
    ).dropna(subset=["Currency"])

    out = df.assign(
        **{
            "æ€»æ¬ æ¬¾": df[owed_col],
            "æ”¶å…¥.1": df[revenue_col],
            "è°ƒæ•´": df[adj_col],
            "é¢„æ‰£ç¨": df[tax_col],
        }
    )[["Currency", "æ€»æ¬ æ¬¾", "æ”¶å…¥.1", "è°ƒæ•´", "é¢„æ‰£ç¨"]]

    # è°ƒè¯•å±•ç¤º
    st.subheader("ğŸ“Š è´¢æŠ¥é¢„è§ˆ")
    st.write("è¯†åˆ«åˆ—ï¼š", {
        "currency_source_col": currency_source_col,
        "revenue_col": revenue_col,
        "owed_col": owed_col,
        "adjust_col": adj_col if adj_col != "__adj__" else "(noneâ†’0)",
        "withholding_col": tax_col if tax_col != "__tax__" else "(noneâ†’0)",
    })
    st.dataframe(out.head())
    return out

def build_rates(df_report):
    """
    æ±‡ç‡ï¼šrate = æœ¬å¸æ€»é¢ / ç¾å…ƒæ”¶å…¥ï¼ˆé€å¸ç§ï¼‰
    åˆ†æ‘Šæ€»é¢(USD)ï¼š((è°ƒæ•´+é¢„æ‰£ç¨)/rate) åˆè®¡
    """
    valid = df_report[(df_report["æ”¶å…¥.1"].notna()) & (df_report["æ”¶å…¥.1"] != 0)]
    if valid.empty:
        raise ValueError("âŒ è´¢æŠ¥ 'æ”¶å…¥.1' å…¨ä¸º 0/ç©ºï¼Œæ— æ³•æ¨å¯¼æ±‡ç‡")
    rates = dict(zip(valid["Currency"], (valid["æ€»æ¬ æ¬¾"] / valid["æ”¶å…¥.1"]).astype(float)))

    df = df_report.copy()
    df["rate"] = df["Currency"].map(rates)
    df["AdjTaxUSD"] = (df["è°ƒæ•´"].fillna(0) + df["é¢„æ‰£ç¨"].fillna(0)) / df["rate"]
    df["AdjTaxUSD"] = pd.to_numeric(df["AdjTaxUSD"], errors="coerce").fillna(0)

    total_adj_usd = float(df["AdjTaxUSD"].sum())
    report_total_usd = float(pd.to_numeric(df["æ”¶å…¥.1"], errors="coerce").sum())
    return rates, total_adj_usd, report_total_usd

# ---------- äº¤æ˜“è¡¨ï¼ˆè‡ªåŠ¨è¯†åˆ« + æ‰‹åŠ¨æ˜ å°„å…œåº•ï¼‰ ----------
def _norm(s: str) -> str:
    s = str(s)
    s = s.strip().lower()
    s = re.sub(r'[\s\-\_\/\.\(\):ï¼Œ,]+', '', s)
    return s

def _auto_guess_columns(cols):
    norm_map = {c: _norm(c) for c in cols}

    # é‡‘é¢åˆ—ï¼ˆä¼˜å…ˆ Extended Partner Share / Proceeds / Amountï¼‰
    eps = None
    for c, n in norm_map.items():
        if ('extended' in n and 'partner' in n and ('share' in n or 'proceeds' in n or 'amount' in n)) \
           or ('partnershareextended' in n) \
           or (('partnershare' in n or 'partnerproceeds' in n) and ('amount' in n or 'gross' in n or 'net' in n)):
            eps = c; break
    if eps is None:
        for c, n in norm_map.items():
            if ('proceeds' in n or 'revenue' in n or 'amount' in n) and ('partner' in n or 'publisher' in n):
                eps = c; break

    # å¸ç§åˆ—
    cur = None
    for c, n in norm_map.items():
        if ('currency' in n) or ('iso' in n and 'code' in n) or n == 'currency':
            cur = c; break
    if cur is None:
        for c, n in norm_map.items():
            if n.endswith('currencycode') or n.endswith('currency'):
                cur = c; break
    if cur is None and 'Currency' in cols:
        cur = 'Currency'

    # SKU åˆ—
    sku = None
    for c, n in norm_map.items():
        if n == 'sku' or n.endswith('sku') or 'productid' in n or n == 'productid' or n == 'itemid':
            sku = c; break
    if sku is None and 'SKU' in cols:
        sku = 'SKU'

    return eps, cur, sku

def read_tx(file):
    df = read_any(file)
    df.columns = [str(c).strip() for c in df.columns]
    st.subheader("ğŸ“Š äº¤æ˜“è¡¨é¢„è§ˆ")
    st.write("åˆ—åï¼š", list(df.columns))
    st.dataframe(df.head())

    eps, cur, sku = _auto_guess_columns(df.columns)
    with st.expander("ğŸ›  æ‰‹åŠ¨åˆ—æ˜ å°„ï¼ˆè‡ªåŠ¨è¯†åˆ«ä¸å‡†æ—¶è¯·è°ƒæ•´ï¼‰", expanded=not (eps and cur and sku)):
        cols = list(df.columns)
        eps = st.selectbox("é‡‘é¢åˆ—ï¼ˆExtended Partner Share / Proceeds / Amountï¼‰", cols, index=(cols.index(eps) if eps in cols else 0))
        cur = st.selectbox("å¸ç§åˆ—ï¼ˆPartner Share Currency / Currencyï¼‰", cols, index=(cols.index(cur) if cur in cols else 0))
        sku = st.selectbox("SKU åˆ—ï¼ˆSKU / Product ID / Item IDï¼‰", cols, index=(cols.index(sku) if sku in cols else 0))

    rename_map = {eps: "Extended Partner Share", cur: "Partner Share Currency", sku: "SKU"}
    df = df.rename(columns=rename_map)

    need = {"Extended Partner Share", "Partner Share Currency", "SKU"}
    missing = need - set(df.columns)
    if missing:
        raise ValueError(f"âŒ äº¤æ˜“è¡¨ä»ç¼ºå°‘åˆ—ï¼š{missing}ï¼›è¯·åœ¨â€œæ‰‹åŠ¨åˆ—æ˜ å°„â€é‡Œé€‰æ‹©æ­£ç¡®çš„åˆ—ã€‚")

    # é‡‘é¢è½¬æ•°å€¼ï¼ˆå»é€—å·ï¼‰
    df["Extended Partner Share"] = df["Extended Partner Share"].astype(str).str.replace(",", "", regex=False)
    df["Extended Partner Share"] = pd.to_numeric(df["Extended Partner Share"], errors="coerce")
    return df

# ---------- æ˜ å°„è¡¨ ----------
def read_map(file):
    df = pd.read_excel(file, engine="openpyxl", dtype=str)
    df.columns = [str(c).strip() for c in df.columns]
    st.subheader("ğŸ“Š æ˜ å°„è¡¨é¢„è§ˆ")
    st.write("åˆ—åï¼š", list(df.columns))
    st.dataframe(df.head())
    if not {"é¡¹ç›®", "SKU"}.issubset(df.columns):
        raise ValueError("âŒ æ˜ å°„è¡¨ç¼ºå°‘åˆ— `é¡¹ç›®` æˆ– `SKU`")
    df = df.assign(SKU=df["SKU"].astype(str).str.split("\n")).explode("SKU")
    df["SKU"] = df["SKU"].str.strip()
    return df[df["SKU"] != ""][["é¡¹ç›®", "SKU"]]

# ---------- ä¸Šä¼ æ§ä»¶ ----------
c1, c2, c3 = st.columns(3)
with c1: tx = st.file_uploader("â‘  äº¤æ˜“æ˜ç»†ï¼ˆCSV/XLSXï¼‰", type=["csv", "xlsx", "xls"], key="tx")
with c2: rp = st.file_uploader("â‘¡ Apple è´¢æŠ¥ï¼ˆCSV/XLSXï¼‰", type=["csv", "xlsx", "xls"], key="rp")
with c3: mp = st.file_uploader("â‘¢ é¡¹ç›®-SKUï¼ˆXLSXï¼‰", type=["xlsx", "xls"], key="mp")

if st.button("ğŸš€ å¼€å§‹è®¡ç®— (Debug+AutoHeader)"):
    if not (tx and rp and mp):
        st.error("âŒ ä¸‰ä»½æ–‡ä»¶æ²¡æœ‰å…¨éƒ¨ä¸Šä¼ ")
    else:
        try:
            rep = read_report(rp)
            rates, total_adj_usd, report_total_usd = build_rates(rep)

            txdf = read_tx(tx)
            txdf["Extended Partner Share USD"] = txdf.apply(
                lambda r: (r["Extended Partner Share"] / rates.get(str(r["Partner Share Currency"]), 1))
                          if pd.notnull(r["Extended Partner Share"]) else None,
                axis=1
            )
            total_usd = pd.to_numeric(txdf["Extended Partner Share USD"], errors="coerce").sum(min_count=1)
            if not pd.notnull(total_usd) or total_usd == 0:
                st.error("âŒ äº¤æ˜“ USD æ±‡æ€»ä¸º 0ï¼Œå¯èƒ½å¸ç§ä¸åŒ¹é…æˆ–é‡‘é¢åˆ—ä¸ºç©º")
                st.stop()

            mpdf = read_map(mp)
            sku2proj = dict(zip(mpdf["SKU"], mpdf["é¡¹ç›®"]))
            txdf["é¡¹ç›®"] = txdf["SKU"].map(sku2proj)

            txdf["Cost Allocation (USD)"] = txdf["Extended Partner Share USD"] / total_usd * total_adj_usd
            txdf["Net Partner Share (USD)"] = txdf["Extended Partner Share USD"] + txdf["Cost Allocation (USD)"]

            summary = txdf.groupby("é¡¹ç›®", dropna=False)[
                ["Extended Partner Share USD", "Cost Allocation (USD)", "Net Partner Share (USD)"]
            ].sum().reset_index()
            total_row = {
                "é¡¹ç›®": "__TOTAL__",
                "Extended Partner Share USD": float(summary["Extended Partner Share USD"].sum()),
                "Cost Allocation (USD)": float(summary["Cost Allocation (USD)"].sum()),
                "Net Partner Share (USD)": float(summary["Net Partner Share (USD)"].sum())
            }
            summary = pd.concat([summary, pd.DataFrame([total_row])], ignore_index=True)

            st.success("âœ… è®¡ç®—å®Œæˆ")
            st.markdown(f"- è´¢æŠ¥ç¾å…ƒæ”¶å…¥åˆè®¡ï¼ˆsum of æ”¶å…¥.1ï¼‰ï¼š**{report_total_usd:,.2f} USD**")
            st.markdown(f"- åˆ†æ‘Šæ€»é¢ï¼ˆè°ƒæ•´+é¢„æ‰£ç¨ï¼‰ï¼š**{total_adj_usd:,.2f} USD**")
            st.markdown(f"- äº¤æ˜“æ¯›æ”¶å…¥ USD åˆè®¡ï¼š**{float(total_usd):,.2f} USD**")

            st.download_button("â¬‡ï¸ ä¸‹è½½ é€å•ç»“æœ CSV",
                               data=txdf.to_csv(index=False).encode("utf-8-sig"),
                               file_name="transactions_usd_net_project.csv", mime="text/csv")
            st.download_button("â¬‡ï¸ ä¸‹è½½ é¡¹ç›®æ±‡æ€» CSV",
                               data=summary.to_csv(index=False).encode("utf-8-sig"),
                               file_name="project_summary.csv", mime="text/csv")

            with st.expander("é¢„è§ˆï¼šé€å•ç»“æœ", expanded=False):
                st.dataframe(txdf.head(100))
            with st.expander("é¢„è§ˆï¼šé¡¹ç›®æ±‡æ€»", expanded=True):
                st.dataframe(summary)

        except Exception as e:
            st.error(f"âš ï¸ å‡ºç°é”™è¯¯ï¼š{e}")
            st.exception(e)
